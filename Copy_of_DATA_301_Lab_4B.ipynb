{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hadiasemi/Data301/blob/main/Copy_of_DATA_301_Lab_4B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByynuurZOPFd"
      },
      "source": [
        "# Song Lyrics Generator\n",
        "\n",
        "In this lab, you will scrape a website to get lyrics of songs by your favorite artist. Then, you will train a model called a Markov chain on these lyrics so that you can generate a song in the style of your favorite artist.\n",
        "\n",
        "# Question 1. Scraping Song Lyrics\n",
        "\n",
        "Find a web site that has lyrics for several songs by your favorite artist. Scrape the lyrics into a Python list called `lyrics`, where each element of the list represents the lyrics of one song.\n",
        "\n",
        "**Tips:**\n",
        "- Find a web page that has links to all of the songs, like [this one](https://www.azlyrics.com/s/stevemillerband.html). [_Note:_ It appears that `azlyrics.com` blocks web scraping, so you may have to find a different lyrics web site.] Then, you can scrape this page, extract the hyperlinks, and issue new HTTP requests to each hyperlink to get each song. \n",
        "- Use `time.sleep()` to stagger your HTTP requests so that you do not get banned by the website for making too many requests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i7B9nidOPFg"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08t7XBKviLeG"
      },
      "outputs": [],
      "source": [
        "response = requests.get(\"https://www.songlyrics.com/soulfly-lyrics/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahh4WBnpiLWs"
      },
      "outputs": [],
      "source": [
        "response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_EknJ38inJR"
      },
      "outputs": [],
      "source": [
        "soup = BeautifulSoup(response.content, \"html.parser\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbiq7kkEOPFl"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "lyrics = []\n",
        "\n",
        "tables = soup.find_all(\"tbody\")\n",
        "\n",
        "for song in tables[0].find_all('tr'):\n",
        "  # find all the links\n",
        "  link = song.find('a',  href=True)\n",
        "  # check to make sure not be None\n",
        "  if link != None:\n",
        "    # go to each link and get the lyric page\n",
        "    get_lyrics = requests.get(link['href'])\n",
        "    soup = BeautifulSoup(get_lyrics.content, \"html.parser\")\n",
        "    lyric = soup.find('p', id ='songLyricsDiv').text\n",
        "    lyric = lyric.replace('\\n' ,' <N> ').replace('[^\\w\\s]','').replace('\\r', '').replace('\\\\', '')\n",
        "    # make sure the lyric is available\n",
        "    if 'We do not have the lyrics for' not in lyric:\n",
        "      lyrics.append(lyric)\n",
        "total_lyrics = []\n",
        "\n",
        "pattern = r'\\[[^\\]]*\\]'\n",
        "for d in lyrics:\n",
        "  total_lyrics.append(re.sub(pattern, '', d))\n",
        "\n",
        "total_lyrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV6GIq9nsCGD",
        "outputId": "a916002e-b439-4e91-888d-3e5c6e5f2995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We the land of carnival and murder <N> Bring the drums and the sounding of thunder <N> Oh my people we got to get stronger <N> With the spirit of war in quilombos <N>  <N> Jungle people, jungle <N> Never underestimate our power <N> Jungle people, jungle <N> Never underestimate our power <N>  <N> Ah, loco <N> Bring the shit <N>  <N> Bring our roots we're under the sun <N> From in the jungle and from the slums <N> Our freedom we bring with this song <N> Never forget where you came from <N>  <N> Jungle people, jungle <N> Never underestimate our power <N> Jungle people, jungle <N> Never underestimate our power <N>  <N> Bumba bumba <N> Bumba bumba <N> Bumba bumba <N>  <N> Oxossi open my way <N> I'm gonna tell the world what you say <N> I know God making me a way <N> We pray, we pray everyday <N>  <N> Jungle people, jungle <N> Never underestimate our power <N> Jungle people, jungle <N> Never underestimate our power <N>  <N> Bumba bumba <N> Bumba bumba <N> Bumba bumba <N>  <N> Ele e caboclo ele e flecheiro bumba na calunga <N> He is land's owner he is archer <N> E matador de feiticeiro bumba na calunga <N> He is killer and witch <N> Ele vai firmar seu ponto bumba na calunga <N> He will assure his point <N> E vai firmar na angola <N> He will assure in angola <N> Bumba na calunga e na fe de oxala <N> Bumba in the calunga and in the faith in oxalÃ¡ <N> Bumba na calunga he is archer <N> Ponto de coboclo sete flechas / t e p j da c <N>  <N> Bumba bumba <N> Bumba bumba <N> Bumba bumba <N> ...\n"
          ]
        }
      ],
      "source": [
        "print(total_lyrics[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9MbbohNOPFt"
      },
      "source": [
        "`pickle` is a Python library that serializes Python objects to disk so that you can load them in later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQI-4UeqOPFu"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(total_lyrics, open(\"lyrics.pkl\", \"wb\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4ddDff6OPFx"
      },
      "source": [
        "# Question 2. Unigram Markov Chain Model\n",
        "\n",
        "You will build a Markov chain for the artist whose lyrics you scraped in Question 1. Your model will process the lyrics and store the word transitions for that artist. The transitions will be stored in a dict called `chain`, which maps each word to a list of \"next\" words.\n",
        "\n",
        "For example, if your song was [\"The Joker\" by the Steve Miller Band](https://www.youtube.com/watch?v=dV3AziKTBUo), `chain` might look as follows:\n",
        "\n",
        "```\n",
        "chain = {\n",
        "    \"some\": [\"people\", \"call\", \"people\"],\n",
        "    \"call\": [\"me\", \"me\", \"me\"],\n",
        "    \"the\": [\"space\", \"gangster\", \"pompitous\", ...],\n",
        "    \"me\": [\"the\", \"the\", \"Maurice\"],\n",
        "    ...\n",
        "}\n",
        "```\n",
        "\n",
        "Besides words, you should include a few additional states in your Markov chain. You should have `\"<START>\"` and `\"<END>\"` states so that we can keep track of how songs are likely to begin and end. You should also include a state called `\"<N>\"` to denote line breaks so that you can keep track of where lines begin and end. It is up to you whether you want to include normalize case and strip punctuation.\n",
        "\n",
        "So for example, for [\"The Joker\"](https://www.azlyrics.com/lyrics/stevemillerband/thejoker.html), you would add the following to your chain:\n",
        "\n",
        "```\n",
        "chain = {\n",
        "    \"<START>\": [\"Some\", ...],\n",
        "    \"Some\": [\"people\", ...],\n",
        "    \"people\": [\"call\", ...],\n",
        "    \"call\": [\"me\", ...],\n",
        "    \"me\": [\"the\", ...],\n",
        "    \"the\": [\"space\", ...],\n",
        "    \"space\": [\"cowboy,\", ...],\n",
        "    \"cowboy,\": [\"yeah\", ...],\n",
        "    \"yeah\": [\"<N>\", ...],\n",
        "    \"<N>\": [\"Some\", ..., \"Come\"],\n",
        "    ...,\n",
        "    \"Come\": [\"on\", ...],\n",
        "    \"on\": [\"baby\", ...],\n",
        "    \"baby\": [\"and\", ...],\n",
        "    \"and\": [\"I'll\", ...],\n",
        "    \"I'll\": [\"show\", ...],\n",
        "    \"show\": [\"you\", ...],\n",
        "    \"you\": [\"a\", ...],\n",
        "    \"a\": [\"good\", ...],\n",
        "    \"good\": [\"time\", ...],\n",
        "    \"time\": [\"<END>\", ...],\n",
        "}\n",
        "```\n",
        "\n",
        "Your chain will be trained on not just one song, but by all songs by your artist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtrBqN8WtTzB"
      },
      "outputs": [],
      "source": [
        "res = []\n",
        "lyric_ = []\n",
        "for i, lyric in enumerate(total_lyrics):\n",
        "  v = (\"<START> \" + lyric + \" <END>\").split()\n",
        "\n",
        "  lyric_.append(v)\n",
        "\n",
        "  \n",
        "lyric_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5P9Bsg6pOPFy"
      },
      "outputs": [],
      "source": [
        "def train_markov_chain(lyrics):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      - lyrics: a list of strings, where each string represents\n",
        "                the lyrics of one song by an artist.\n",
        "    \n",
        "    Returns:\n",
        "      A dict that maps a single word (\"unigram\") to a list of\n",
        "      words that follow that word, representing the Markov\n",
        "      chain trained on the lyrics.\n",
        "    \"\"\"\n",
        "\n",
        "    chain = {\"<START>\": []}\n",
        "    for lyric in lyrics:\n",
        "        # YOUR CODE HERE\n",
        "        for i, word in enumerate(lyric):\n",
        "          if word != \"<END>\":\n",
        "            if word not in chain.keys():\n",
        "              chain[word] = [lyric[i+1]]\n",
        "            else:\n",
        "              chain[word].append(lyric[i+1]) if lyric[i+1] not in chain[word] else 1\n",
        "          \n",
        "\n",
        "    return chain\n",
        "train_markov_chain(lyric_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewkgeMyQOPF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e8b8224-5018-42d8-bcbb-65935de64813"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['We', 'In', 'Up', 'Jump', 'Fall', 'Bumba,', 'Pablo', 'Um', 'The', 'Die,', '*Zumbi', 'Here', 'I', 'What', 'Fire,', 'When', 'Pressure', 'This', '<END>', 'On', 'Um,', 'Off', '<N>', 'My', 'Impaled', 'Blood,', '*we', 'Counter', 'Shame', 'Sacred', 'Judas…', 'Ð', 'Live', 'Zumbi', 'Lightning', 'Speak', 'Disciple', 'Lost', 'One,', 'Time', 'Yo,', 'Grow', 'Feels', 'Every', 'Manananananaue', 'Vamos', 'Maggots', 'Clean', 'War', 'Material', 'Monday,', 'Spreading', 'You', 'All', 'No', 'Dark', 'Bezouro,', 'Carved', 'Oh,', 'Whoever', 'Murderer', 'Why', 'Now', 'Extreme...', 'Fighting', 'Earth', 'So', 'Welcome', 'Doomsday', 'Keep', 'Wings', 'Born', 'Feel', 'Mulambo', \"I'm\", 'Vulture', 'Porrada', 'Instrumental', 'Prophecies', 'Namaste', '*', 'Quilombo', 'Told', 'SoulFly', 'No,', 'Brainwashed', 'Chaos', 'INTRO:', 'Roots', 'Master', 'And', 'Fuck', 'Your', 'Oh', 'Prophecy', 'live', 'Sorry,', 'Intro]', 'Featuring', 'Jumpdafuckup!', 'Fire...', 'Judas...', 'Bloody', 'Brethren,', 'Fight', 'Rome', \"We're\", 'Well,', 'Shed...']\n",
            "['Bring', 'Oh', 'With', '<N>', 'Jungle', 'Never', 'Ah,', 'From', 'Our', 'Bumba', 'Oxossi', \"I'm\", 'I', 'We', 'Ele', 'He', 'E', 'Ponto', '...', 'Body']\n"
          ]
        }
      ],
      "source": [
        "# Load the pickled lyrics object that you created in Question 1.\n",
        "import pickle\n",
        "lyrics = pickle.load(open(\"lyrics.pkl\", \"rb\"))\n",
        "\n",
        "# Call the function you wrote above.\n",
        "chain = train_markov_chain(lyric_)\n",
        "\n",
        "# What words tend to start a song (i.e., what words follow the <START> tag?)\n",
        "print(chain[\"<START>\"])\n",
        "\n",
        "# What words tend to begin a line (i.e., what words follow the line break tag?)\n",
        "print(chain[\"<N>\"][:20])\n",
        "\n",
        "# import random\n",
        "# print(random.choice(chain[\"<START>\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkdEbg7HOPF5"
      },
      "source": [
        "Now, let's generate new lyrics using the Markov chain you constructed above. To do this, we'll begin at the `\"<START>\"` state and randomly sample a word from the list of words that follow `\"<START>\"`. Then, at each step, we'll randomly sample the next word from the list of words that followed each current word. We will continue this process until we sample the `\"<END>\"` state. This will give us the complete lyrics of a randomly generated song!\n",
        "\n",
        "You may find the `random.choice()` function helpful for this question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsFHxt0XOPF6"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def generate_new_lyrics(chain):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      - chain: a dict representing the Markov chain,\n",
        "               such as one generated by generate_new_lyrics()\n",
        "    \n",
        "    Returns:\n",
        "      A string representing the randomly generated song.\n",
        "    \"\"\"\n",
        "    \n",
        "    # a list for storing the generated words\n",
        "    words = []\n",
        "    # generate the first word\n",
        "    word = random.choice(chain[\"<START>\"])\n",
        "    \n",
        "    # YOUR CODE HERE\n",
        "    while word != \"<END>\":\n",
        "        words.append(word)\n",
        "        word = random.choice(chain[word])\n",
        "\n",
        "    \n",
        "    \n",
        "    # join the words together into a string with line breaks\n",
        "    lyrics = \" \".join(words[:-1])\n",
        "    return \"\\n\".join(lyrics.split(\"<N>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmop55SGOPF-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3fb07df-8900-4608-962d-25124ef943d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We the land do this \n",
            " And everything turns inside out \n",
            " You can't mask pain, my pain, our\n"
          ]
        }
      ],
      "source": [
        "print(generate_new_lyrics(chain))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjwB8aiMOPGE"
      },
      "source": [
        "# Question 3. Bigram Markov Chain Model\n",
        "\n",
        "Now you'll build a more complex Markov chain that uses the last _two_ words (or bigram) to predict the next word. Now your dict `chain` should map a _tuple_ of words to a list of words that appear after it.\n",
        "\n",
        "As before, you should also include tags that indicate the beginning and end of a song, as well as line breaks. That is, a tuple might contain tags like `\"<START>\"`, `\"<END>\"`, and `\"<N>\"`, in addition to regular words. So for example, for [\"The Joker\"](https://www.azlyrics.com/lyrics/stevemillerband/thejoker.html), you would add the following to your chain:\n",
        "\n",
        "```\n",
        "chain = {\n",
        "    (None, \"<START>\"): [\"Some\", ...],\n",
        "    (\"<START>\", \"Some\"): [\"people\", ...],\n",
        "    (\"Some\", \"people\"): [\"call\", ...],\n",
        "    (\"people\", \"call\"): [\"me\", ...],\n",
        "    (\"call\", \"me\"): [\"the\", ...],\n",
        "    (\"me\", \"the\"): [\"space\", ...],\n",
        "    (\"the\", \"space\"): [\"cowboy,\", ...],\n",
        "    (\"space\", \"cowboy,\"): [\"yeah\", ...],\n",
        "    (\"cowboy,\", \"yeah\"): [\"<N>\", ...],\n",
        "    (\"yeah\", \"<N>\"): [\"Some\", ...],\n",
        "    (\"time\", \"<N>\"): [\"Come\"],\n",
        "    ...,\n",
        "    (\"<N>\", \"Come\"): [\"on\", ...],\n",
        "    (\"Come\", \"on\"): [\"baby\", ...],\n",
        "    (\"on\", \"baby\"): [\"and\", ...],\n",
        "    (\"baby\", \"and\"): [\"I'll\", ...],\n",
        "    (\"and\", \"I'll\"): [\"show\", ...],\n",
        "    (\"I'll\", \"show\"): [\"you\", ...],\n",
        "    (\"show\", \"you\"): [\"a\", ...],\n",
        "    (\"you\", \"a\"): [\"good\", ...],\n",
        "    (\"a\", \"good\"): [\"time\", ...],\n",
        "    (\"good\", \"time\"): [\"<END>\", ...],\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQQf5qfLOPGF"
      },
      "outputs": [],
      "source": [
        "def train_markov_chain(lyrics):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      - lyrics: a list of strings, where each string represents\n",
        "                the lyrics of one song by an artist.\n",
        "    \n",
        "    Returns:\n",
        "      A dict that maps a tuple of 2 words (\"bigram\") to a list of\n",
        "      words that follow that bigram, representing the Markov\n",
        "      chain trained on the lyrics.\n",
        "    \"\"\"\n",
        "    chain = {(None, \"<START>\"): []}\n",
        "    for lyric in lyrics:\n",
        "        # YOUR CODE HERE\n",
        "        lines = lyric.split()\n",
        "        bigram = (None, \"<START>\")\n",
        "        for word in lines:\n",
        "            chain[bigram].append(word)\n",
        "            bigram = (bigram[1], word)\n",
        "            if bigram not in chain:\n",
        "                chain[bigram] = []\n",
        "        chain[bigram].append(\"<END>\")\n",
        "\n",
        "    return chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpPtRfOxOPGI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f554f1ab-bdbe-4ec4-cc52-03eb77e7577f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['We', 'In', 'Up', 'Jump', 'Fall', 'Bumba,', 'Pablo', 'Um', 'The', 'Die,', 'Jump', '*Zumbi', 'Here', 'I', 'What', 'Fire,', 'When', 'Pressure', 'This', '<END>', 'We', 'On', 'Um,', 'Off', '<N>', 'My', 'This', 'Impaled', 'Blood,', '*we', 'Counter', 'Shame', 'Sacred', 'I', 'I', 'Judas…', 'Ð', 'Live', 'Zumbi', 'Lightning', 'Speak', 'Disciple', 'Lost', 'One,', 'Time', 'Yo,', 'Grow', 'Feels', 'Every', 'What', 'Pressure', 'Manananananaue', 'Vamos', 'Maggots', 'My', 'Clean', 'War', 'Material', 'Monday,', 'Spreading', 'I', 'You', '<N>', 'All', 'I', 'No', 'You', 'Dark', 'Bezouro,', 'Carved', '<END>', 'Oh,', 'Whoever', 'No', 'Murderer', 'Why', 'Now', 'Extreme...', '<END>', 'Fighting', 'Earth', '<END>', 'The', 'Zumbi', 'So', 'Welcome', 'Doomsday', 'Keep', 'We', 'My', '<END>', 'Wings', 'You', 'Born', 'Feel', 'Mulambo', \"I'm\", 'The', 'Whoever', 'Vulture', 'Now', 'Porrada', 'Instrumental', '<END>', '<END>', 'I', 'Prophecies', 'Namaste', '<END>', '*', \"I'm\", 'Quilombo', 'Told', 'Grow', 'The', 'What', 'Born', 'SoulFly', 'Keep', 'This', 'No,', 'Brainwashed', 'Brainwashed', 'Chaos', 'Brainwashed', 'Fire,', 'Yo,', 'Zumbi', 'Here', 'INTRO:', 'Roots', 'Chaos', 'I', 'I', '*Zumbi', 'Chaos', 'Roots', 'Master', 'And', 'We', 'Master', 'War', 'Brainwashed', 'The', 'Fighting', 'I', 'Feel', 'The', 'Fuck', 'This', '*we', 'Um,', 'Quilombo', 'No', '*Zumbi', 'Your', 'Oh', 'Murderer', 'Fuck', '*Zumbi', 'Quilombo', 'I', '*Zumbi', 'Quilombo', '*we', 'Um,', '*Zumbi', 'Here', 'No', 'I', '<N>', 'We', 'This', 'Shame', 'Roots', 'Live', 'Murderer', 'Prophecy', 'What', 'Wings', 'I', 'live', 'Sorry,', 'What', 'Intro]', '<N>', '<N>', '<N>', '<N>', '<N>', 'Featuring', '<N>', '<N>', 'Instrumental', 'I', 'Whoever', 'Born', 'Fighting', 'Jumpdafuckup!', 'Vulture', 'Fire...', 'Master', 'Judas...', 'Jumpdafuckup!', 'Judas…', 'Bloody', 'Brethren,', 'Fight', 'Rome', \"We're\", 'In', 'Jumpdafuckup!', 'Roots', 'I', 'Feel', 'Um,', 'Whoever', 'Here', 'Well,', 'I', 'Speak', 'Spreading', 'Um,', 'Roots', 'Shed...']\n"
          ]
        }
      ],
      "source": [
        "# Load the pickled lyrics object that you created in Question 1.\n",
        "import pickle\n",
        "lyrics = pickle.load(open(\"lyrics.pkl\", \"rb\"))\n",
        "\n",
        "# Call the function you wrote above.\n",
        "chain = train_markov_chain(lyrics)\n",
        "\n",
        "# What words tend to start a song (i.e., what words follow the <START> tag?)\n",
        "print(chain[(None, \"<START>\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rih6gnzOPGL"
      },
      "source": [
        "Now, let's generate new lyrics using the Markov chain you constructed above. To do this, we'll begin at the `(None, \"<START>\")` state and randomly sample a word from the list of words that follow this bigram. Then, at each step, we'll randomly sample the next word from the list of words that followed the current bigram (i.e., the last two words). We will continue this process until we sample the `\"<END>\"` state. This will give us the complete lyrics of a randomly generated song!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmtEgsDoOPGM"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def generate_new_lyrics(chain):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      - chain: a dict representing the Markov chain,\n",
        "               such as one generated by generate_new_lyrics()\n",
        "    \n",
        "    Returns:\n",
        "      A string representing the randomly generated song.\n",
        "    \"\"\"\n",
        "    \n",
        "    # a list for storing the generated words\n",
        "    words = []\n",
        "    # generate the first word\n",
        "    words.append(random.choice(chain[(None, \"<START>\")]))\n",
        "    \n",
        "    bigram = (\"<START>\",words[0])\n",
        "    word = random.choice(chain[bigram])\n",
        "\n",
        "    while word != \"<END>\":\n",
        "        words.append(word)\n",
        "        bigram = (words[-2], words[-1])\n",
        "        word = random.choice(chain[bigram])\n",
        "    \n",
        "    # join the words together into a string with line breaks\n",
        "    lyrics = \" \".join(words[:-1])\n",
        "    return \"\\n\".join(lyrics.split(\"<N>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPPTdLloOPGO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffccfed9-6522-44ce-b5e3-2409d4c7880f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " The seven gates of Namtar fell \n",
            " Jfk shot in the calunga and in your brain \n",
            " \n",
            " This corrosion creeps \n",
            " And limb amputations \n",
            " \n",
            " Come around, come around \n",
            " Now motivation comes from beyond \n",
            " Bloodbath \n",
            " Tyrants \n",
            " Bastards \n",
            " \n",
            " I hit the bottom \n",
            " You know we can't pretend \n",
            " Here we go \n",
            " Another day, another hour \n",
            " Here we go \n",
            " \n",
            " What we want to burn \n",
            " Starting to burn up the scene \n",
            " Trust no soul \n",
            " \n",
            " Against all odds we carry on \n",
            " \n",
            " Here we go \n",
            " I'd rather die on my feet \n",
            " Here we go \n",
            " It's All We Wanna Be \n",
            " Watch us\n"
          ]
        }
      ],
      "source": [
        "print(generate_new_lyrics(chain))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUEJzOtnOPGR"
      },
      "source": [
        "# Question 4. Analysis\n",
        "\n",
        "Compare the quality of the lyrics generated by the unigram model (in Question 2) and the bigram model (in Question 3). Which model seems to generate more reasonable lyrics? Can you explain why? What do you see as the advantages and disadvantages of each model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k2Hym0UOPGS"
      },
      "source": [
        "In my perspective the bigram has more quilty to it compare to the unigram. Also, the bigram generate longer length compare to unigram. As result, the bigram generate more reseanable model compare to unigram. The issue that I can see in both is they both include lots of repitation in the lyrics generated. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJYlXhArOPGT"
      },
      "source": [
        "## Submission Instructions\n",
        "\n",
        "- Restart this notebook and run the cells from beginning to end:\n",
        "  - Go to Runtime > Restart and Run All.\n",
        "- Download the notebook:\n",
        "  - Go to File > Download > Download .ipynb.\n",
        "- Submit your notebook file to the assignment on Canvas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QR8bJUE_B1pS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of DATA 301 Lab 4B",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}