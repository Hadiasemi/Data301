{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Copy of DATA 301 Lab 6A",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hadiasemi/Data301/blob/main/Copy_of_DATA_301_Lab_6A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWSNdW_jY8DY"
      },
      "source": [
        "# Machine Learning for Beer\n",
        "\n",
        "Your goal is to train a model to predict the bitterness of a beer (in International Bittering Units, or IBU), given features about the beer. You can acquire the data in any one of three places:\n",
        "\n",
        "- on [Kaggle](https://www.kaggle.com/competitions/beer2022ventura/data) \n",
        "- on [Github](https://github.com/dlsun/pods/tree/master/data/beer) (https://dlsun.github.io/pods/data/beer/beer_train.csv and https://dlsun.github.io/pods/data/beer/beer_test.csv )\n",
        "\n",
        "A description of the variables is available [here](https://www.kaggle.com/competitions/beer2022ventura/data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgaFvqueY8Dc"
      },
      "source": [
        "## Question 1\n",
        "\n",
        "You would like to predict **ibu** using a $20$-nearest neighbors model. You are choosing between 4 sets of features to put into this model:\n",
        "\n",
        "1. **abv**\n",
        "2. **abv**, **name**\n",
        "3. **abv**, **name**, **available**\n",
        "4. **abv**, **name**, **available**, **glass**\n",
        "\n",
        "Apply TF-IDF (using the top 100 terms) to the raw text variables and one-hot encoding to the categorical variables.  (It is up to you which variables to treat as categorical and which to treat as raw text.)\n",
        "\n",
        "\n",
        "For each set of features, train a $20$-nearest neighbor model to predict IBU (**ibu**). Which of these models is best for predicting IBU? Justify your answer."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "import numpy as np\n",
        "\n",
        "df_beer_train = pd.read_csv(\"https://dlsun.github.io/pods/data/beer/beer_train.csv\")\n",
        "df_beer_train.head()"
      ],
      "metadata": {
        "id": "Jp633bLE3pB2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "cdbf97c3-6343-4d75-fd66-bfca30c2bd9c"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  abv                                        available  \\\n",
              "0   0  8.2  Available at the same time of year, every year.   \n",
              "1   1  5.7  Available at the same time of year, every year.   \n",
              "2   2  5.8  Available at the same time of year, every year.   \n",
              "3   3  5.5           Available year round as a staple beer.   \n",
              "4   4  4.8           Available year round as a staple beer.   \n",
              "\n",
              "                                         description glass   ibu isOrganic  \\\n",
              "0  A Belgian-Abbey-Style Tripel that is big in al...   NaN  31.0         N   \n",
              "1  Covert Hops is a crafty ale. Its stealthy dark...  Pint  45.0         N   \n",
              "2  This is a traditional German-style Marzen char...   Mug  25.0         N   \n",
              "3  A West Coast-Style Pale Ale balancing plenty o...  Pint  55.0         N   \n",
              "4  This Bombshell has a tantalizing crisp and cle...  Pint  11.4         N   \n",
              "\n",
              "                     name  originalGravity srm  \n",
              "0         LoonyToonTripel            1.070   8  \n",
              "1             Covert Hops            1.056  35  \n",
              "2             Oktoberfest            1.048  10  \n",
              "3                Pale Ale            1.044   5  \n",
              "4  Head Turner Blonde Ale            1.045   3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b3b16e1-3667-4598-aed8-4fa428fb5571\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>abv</th>\n",
              "      <th>available</th>\n",
              "      <th>description</th>\n",
              "      <th>glass</th>\n",
              "      <th>ibu</th>\n",
              "      <th>isOrganic</th>\n",
              "      <th>name</th>\n",
              "      <th>originalGravity</th>\n",
              "      <th>srm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>8.2</td>\n",
              "      <td>Available at the same time of year, every year.</td>\n",
              "      <td>A Belgian-Abbey-Style Tripel that is big in al...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31.0</td>\n",
              "      <td>N</td>\n",
              "      <td>LoonyToonTripel</td>\n",
              "      <td>1.070</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>5.7</td>\n",
              "      <td>Available at the same time of year, every year.</td>\n",
              "      <td>Covert Hops is a crafty ale. Its stealthy dark...</td>\n",
              "      <td>Pint</td>\n",
              "      <td>45.0</td>\n",
              "      <td>N</td>\n",
              "      <td>Covert Hops</td>\n",
              "      <td>1.056</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5.8</td>\n",
              "      <td>Available at the same time of year, every year.</td>\n",
              "      <td>This is a traditional German-style Marzen char...</td>\n",
              "      <td>Mug</td>\n",
              "      <td>25.0</td>\n",
              "      <td>N</td>\n",
              "      <td>Oktoberfest</td>\n",
              "      <td>1.048</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>5.5</td>\n",
              "      <td>Available year round as a staple beer.</td>\n",
              "      <td>A West Coast-Style Pale Ale balancing plenty o...</td>\n",
              "      <td>Pint</td>\n",
              "      <td>55.0</td>\n",
              "      <td>N</td>\n",
              "      <td>Pale Ale</td>\n",
              "      <td>1.044</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4.8</td>\n",
              "      <td>Available year round as a staple beer.</td>\n",
              "      <td>This Bombshell has a tantalizing crisp and cle...</td>\n",
              "      <td>Pint</td>\n",
              "      <td>11.4</td>\n",
              "      <td>N</td>\n",
              "      <td>Head Turner Blonde Ale</td>\n",
              "      <td>1.045</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b3b16e1-3667-4598-aed8-4fa428fb5571')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b3b16e1-3667-4598-aed8-4fa428fb5571 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b3b16e1-3667-4598-aed8-4fa428fb5571');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error = pd.Series()\n",
        "\n",
        "ct = make_column_transformer(\n",
        "    (StandardScaler(), [\"abv\"]),\n",
        "    remainder=\"drop\"  # all other columns in X will be dropped.\n",
        ")\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "  ct,\n",
        "  KNeighborsRegressor(n_neighbors=20)\n",
        ")\n",
        "\n",
        "# calculate errors from cross-validation\n",
        "cv_errs = -cross_val_score(pipeline, X=df_beer_train[['abv']],\n",
        "                            y=df_beer_train[\"ibu\"],\n",
        "                            scoring=\"neg_mean_squared_error\", cv=10)\n",
        "\n",
        "# calculate average of the cross-validation errors\n",
        "error['abv'] = cv_errs.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SktnPG3Q5SrZ",
        "outputId": "15995778-011e-4615-9c1b-6146427c68a5"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
        "ct = make_column_transformer(\n",
        "    (StandardScaler(), [\"abv\"]),\n",
        "    (TfidfVectorizer(norm=None, max_features=100), \"name\"),\n",
        "    remainder=\"drop\"  # all other columns in X will be dropped.\n",
        ")\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "  ct,\n",
        "  KNeighborsRegressor(n_neighbors=20)\n",
        ")\n",
        "\n",
        "# calculate errors from cross-validation\n",
        "cv_errs = -cross_val_score(pipeline, X=df_beer_train[['abv', \"name\"]],\n",
        "                            y=df_beer_train[\"ibu\"],\n",
        "                            scoring=\"neg_mean_squared_error\", cv=10)\n",
        "\n",
        "# calculate average of the cross-validation errors\n",
        "error[\"abv, name\"] =cv_errs.mean()"
      ],
      "metadata": {
        "id": "QtPl9Vu571W4"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct = make_column_transformer(\n",
        "    (StandardScaler(), [\"abv\"]),\n",
        "    (TfidfVectorizer(norm=None, max_features=100), \"name\"),\n",
        "    (OneHotEncoder(handle_unknown='ignore'), ['available']),\n",
        "    remainder=\"drop\"  # all other columns in X will be dropped.\n",
        ")\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "  ct,\n",
        "  KNeighborsRegressor(n_neighbors=20)\n",
        ")\n",
        "\n",
        "# calculate errors from cross-validation\n",
        "cv_errs = -cross_val_score(pipeline, X=df_beer_train[['abv', \"name\", 'available']],\n",
        "                            y=df_beer_train[\"ibu\"],\n",
        "                            scoring=\"neg_mean_squared_error\", cv=10)\n",
        "\n",
        "# calculate average of the cross-validation errors\n",
        "error['abv, name, available'] = cv_errs.mean()"
      ],
      "metadata": {
        "id": "StsW2Qpu9tow"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_beer_train['glass'] = df_beer_train['glass'].fillna(\"Now\")\n",
        "ct = make_column_transformer(\n",
        "    (StandardScaler(), [\"abv\"]),\n",
        "    (TfidfVectorizer(norm = None, max_features=100), \"name\"),\n",
        "    (OneHotEncoder(handle_unknown='ignore'), ['available', 'glass']),\n",
        "    remainder=\"drop\"  # all other columns in X will be dropped.\n",
        ")\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "  ct,\n",
        "  KNeighborsRegressor(n_neighbors=20)\n",
        ")\n",
        "\n",
        "# calculate errors from cross-validation\n",
        "cv_errs = -cross_val_score(pipeline, X=df_beer_train[['abv', \"name\", 'available', 'glass']],\n",
        "                            y=df_beer_train[\"ibu\"],\n",
        "                            scoring=\"neg_mean_squared_error\", cv=10)\n",
        "\n",
        "# calculate average of the cross-validation errors\n",
        "error['abv, name, available, glass'] = cv_errs.mean()"
      ],
      "metadata": {
        "id": "CsTomGrZ-ZHX"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "np.sqrt(error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi7Du4rkAP5y",
        "outputId": "564c6ea0-617d-491e-99e2-345613cd1f7f"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "abv                            25.501843\n",
              "abv, name                      23.741901\n",
              "abv, name, available           23.740033\n",
              "abv, name, available, glass    23.577605\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fourth one is best one to choose with error 23.577605."
      ],
      "metadata": {
        "id": "4FPOMft8Cab7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEBlEDxWY8Dl"
      },
      "source": [
        "## Question 2\n",
        "\n",
        "Let's see how the distance metric and the scaling method influence prediction accuracy. Use the set of features from Question 1 that you determined to be the best. Continue to use $k=20$ nearest neighbors, but try fitting models with different distance metrics and scaling methods. Which distance metric and/or scaling method gives the best prediction accuracy?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler"
      ],
      "metadata": {
        "id": "NGNyaGOhh7P6"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors = pd.Series()\n",
        "\n",
        "df_beer_train['glass'] = df_beer_train['glass'].fillna(\"Now\")\n",
        "ct = make_column_transformer(\n",
        "    (StandardScaler(), [\"abv\"]),\n",
        "    (TfidfVectorizer(norm = None, max_features=100), \"name\"),\n",
        "    (OneHotEncoder(handle_unknown='ignore'), ['available', 'glass']),\n",
        "    remainder=\"drop\"  # all other columns in X will be dropped.\n",
        ")\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "  ct,\n",
        "  KNeighborsRegressor(n_neighbors=20, p=1) # manhattan_distance\n",
        ")\n",
        "\n",
        "# calculate errors from cross-validation\n",
        "cv_errs = -cross_val_score(pipeline, X=df_beer_train[['abv', \"name\", 'available', 'glass']],\n",
        "                            y=df_beer_train[\"ibu\"],\n",
        "                            scoring=\"neg_mean_squared_error\", cv=10)\n",
        "\n",
        "# calculate average of the cross-validation errors\n",
        "errors['Standard Scalar, Manhatan Dist'] = np.sqrt(cv_errs.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOEZXBn5DL9P",
        "outputId": "9445b77d-5253-4f81-b2d9-47b00c20f7c8"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_beer_train['glass'] = df_beer_train['glass'].fillna(\"Now\")\n",
        "ct = make_column_transformer(\n",
        "    (RobustScaler(), [\"abv\"]),\n",
        "    (TfidfVectorizer(norm = None, max_features=100), \"name\"),\n",
        "    (OneHotEncoder(handle_unknown='ignore'), [\"available\", \"glass\"]),\n",
        "    remainder=\"drop\"  # all other columns in X will be dropped.\n",
        ")\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "  ct,\n",
        "  KNeighborsRegressor(n_neighbors=20) # euclidean_distance\n",
        ")\n",
        "\n",
        "# calculate errors from cross-validation\n",
        "cv_errs = -cross_val_score(pipeline, X=df_beer_train[['abv', \"name\", 'available', 'glass']],\n",
        "                            y=df_beer_train[\"ibu\"],\n",
        "                            scoring=\"neg_mean_squared_error\", cv=10)\n",
        "\n",
        "# calculate average of the cross-validation errors\n",
        "errors['Robust Scalar, Eculidian Dist'] = np.sqrt(cv_errs.mean())"
      ],
      "metadata": {
        "id": "egMf7YUkZfoJ"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_beer_train['glass'] = df_beer_train['glass'].fillna(\"Now\")\n",
        "ct = make_column_transformer(\n",
        "    (RobustScaler(), [\"abv\"]),\n",
        "    (TfidfVectorizer(norm = None, max_features=100), \"name\"),\n",
        "    (OneHotEncoder(handle_unknown='ignore'), ['available', 'glass']),\n",
        "    remainder=\"drop\"  # all other columns in X will be dropped.\n",
        ")\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "  ct,\n",
        "  KNeighborsRegressor(n_neighbors=20, p=1) # manhattan_distance\n",
        ")\n",
        "\n",
        "# calculate errors from cross-validation\n",
        "cv_errs = -cross_val_score(pipeline, X=df_beer_train[['abv', \"name\", 'available', 'glass']],\n",
        "                            y=df_beer_train[\"ibu\"],\n",
        "                            scoring=\"neg_mean_squared_error\", cv=10)\n",
        "\n",
        "# calculate average of the cross-validation errors\n",
        "errors['Robust Scalar, Manhatan Dist'] = np.sqrt(cv_errs.mean())"
      ],
      "metadata": {
        "id": "Y2ZmGRMyezsO"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_beer_train['glass'] = df_beer_train['glass'].fillna(\"Now\")\n",
        "ct = make_column_transformer(\n",
        "    (StandardScaler(), [\"abv\"]),\n",
        "    (TfidfVectorizer(norm = None, max_features=100), \"name\"),\n",
        "    (OneHotEncoder(handle_unknown='ignore'), ['available', 'glass']),\n",
        "    remainder=\"drop\"  # all other columns in X will be dropped.\n",
        ")\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "  ct,\n",
        "  KNeighborsRegressor(n_neighbors=20) # manhattan_distance\n",
        ")\n",
        "\n",
        "# calculate errors from cross-validation\n",
        "cv_errs = -cross_val_score(pipeline, X=df_beer_train[['abv', \"name\", 'available', 'glass']],\n",
        "                            y=df_beer_train[\"ibu\"],\n",
        "                            scoring=\"neg_mean_squared_error\", cv=10)\n",
        "\n",
        "# calculate average of the cross-validation errors\n",
        "errors['Standard Scalar, Eculidian Dist'] = np.sqrt(cv_errs.mean())"
      ],
      "metadata": {
        "id": "safbGyF3jYjb"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPBYJ5z4jjHW",
        "outputId": "b0eb7529-c4f1-4650-c68b-6c2348694623"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Standard Scalar, Manhatan Dist     23.241898\n",
              "Robust Scalar, Eculidian Dist      23.594698\n",
              "Robust Scalar, Manhatan Dist       23.225148\n",
              "Standard Scalar, Eculidian Dist    23.577605\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the result I got the least error for the **Robust Scalar, Manhatan Dist :23.225148**"
      ],
      "metadata": {
        "id": "ob7568_ZlB_D"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_uFz0BaY8Ds"
      },
      "source": [
        "## Question 3\n",
        "\n",
        "Finally, let's determine the right value of $k$. Use the set of features, the distance metric, and the scaling method that you determined to be best (for $k=20$) in Questions 1 and 2. Fit $k$-nearest neighbor models for different values of $k$. Plot the training error and the estimated test error as functions of $k$, and determine the optimal value of $k$."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "IEJkuyciljp6"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct = make_column_transformer(\n",
        "    (RobustScaler(), [\"abv\"]),\n",
        "    (TfidfVectorizer(norm = None, max_features = 100), \"name\"),\n",
        "    (OneHotEncoder(handle_unknown='ignore'), [\"available\", \"glass\"]),\n",
        "    remainder=\"drop\"  # all other columns in X will be dropped.\n",
        ")\n",
        "pipeline = make_pipeline(\n",
        "  ct,\n",
        "  KNeighborsRegressor(p=1)\n",
        ")\n",
        "\n",
        "X_train = df_beer_train[['abv','name','available','glass']]\n",
        "y_train = df_beer_train['ibu']\n",
        "\n",
        "grid_search = GridSearchCV(pipeline,\n",
        "                           param_grid={\n",
        "                               \"kneighborsregressor__n_neighbors\": range(1, 20)\n",
        "                           },\n",
        "                           scoring=\"neg_mean_absolute_error\",\n",
        "                           cv=10)\n",
        "grid_search.fit(X_train, y_train)\n",
        "grid_search.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtQYvbFzlwhu",
        "outputId": "6895ec7f-8ed0-4c15-e3a2-b7368b4b682d"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('columntransformer',\n",
              "                 ColumnTransformer(transformers=[('robustscaler',\n",
              "                                                  RobustScaler(), ['abv']),\n",
              "                                                 ('tfidfvectorizer',\n",
              "                                                  TfidfVectorizer(max_features=100,\n",
              "                                                                  norm=None),\n",
              "                                                  'name'),\n",
              "                                                 ('onehotencoder',\n",
              "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
              "                                                  ['available', 'glass'])])),\n",
              "                ('kneighborsregressor',\n",
              "                 KNeighborsRegressor(n_neighbors=17, p=1))])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22_pXlcHRC6D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "outputId": "a7e0866a-3f0d-4bf4-e4c7-ccda48bba17b"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "X_train = df_beer_train[['abv','name','available','glass']]\n",
        "y_train = df_beer_train['ibu']\n",
        "\n",
        "\n",
        "# calculate estimate of test error for a value of k\n",
        "def get_cv_error(k):\n",
        "  # define pipeline\n",
        "  pipeline = make_pipeline(\n",
        "  ct,\n",
        "  KNeighborsRegressor(n_neighbors=k, p=1)\n",
        "  )\n",
        "\n",
        "  # calculate errors from cross-validation\n",
        "  cv_errs = -cross_val_score(pipeline, X=X_train, y=y_train,\n",
        "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
        "  # calculate average of the cross-validation errors\n",
        "  return cv_errs.mean()\n",
        "    \n",
        "ks = pd.Series(range(1, 20))\n",
        "ks.index = range(1, 20)\n",
        "test_errs = ks.apply(get_cv_error)\n",
        "test_errs\n",
        "test_errs.plot.line()\n",
        "test_errs.sort_values()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18    538.750078\n",
              "17    539.077787\n",
              "19    540.506882\n",
              "16    541.120942\n",
              "15    542.051523\n",
              "14    544.698066\n",
              "13    545.735100\n",
              "12    549.334882\n",
              "11    555.178446\n",
              "10    558.297210\n",
              "9     561.143195\n",
              "8     571.418608\n",
              "7     573.166703\n",
              "6     582.211138\n",
              "5     594.458795\n",
              "4     619.993625\n",
              "3     654.106215\n",
              "2     765.718442\n",
              "1     985.079022\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 98
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on GridSearchCV I got k = 17 from range of 1 to 20. With other method of calculation error for the k, I got 18."
      ],
      "metadata": {
        "id": "UWjU1Px7rikU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhRFqKSDY8D2"
      },
      "source": [
        "## Submission Instructions\n",
        "\n",
        "- Restart this notebook and run the cells from beginning to end:\n",
        "  - Go to Runtime > Restart and Run All.\n",
        "- Download the notebook:\n",
        "  - Go to File > Download > Download .ipynb.\n",
        "- Submit your notebook file to the assignment on Canvas."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nFZHie-4GZyq"
      },
      "execution_count": 94,
      "outputs": []
    }
  ]
}