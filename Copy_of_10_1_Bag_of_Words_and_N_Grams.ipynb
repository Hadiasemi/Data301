{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Copy of 10.1 Bag of Words and N-Grams.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hadiasemi/Data301/blob/main/Copy_of_10_1_Bag_of_Words_and_N_Grams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k5RX60yP9hv"
      },
      "source": [
        "# Chapter 10 Textual Data\n",
        "\n",
        "You may not naturally think of _text_, like an e-mail or a newspaper article, as data. But just as we might predict the price of a home or cluster wines into similar types, we might want to predict the sender of an e-mail or cluster articles into similar types. To leverage the machine learning techniques from Part II of this book, we will need to convert raw text into tabular form. This chapter introduces some principles for doing so."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weXLO3u5P9hy"
      },
      "source": [
        "# 10.1 Bag of Words and N-Grams\n",
        "\n",
        "In data science, a unit of text is typically called a _document_, even though a document can be anything from a text message to a full-length novel.  A collection of documents is called a _corpus_. In this lesson, we will work with a corpus of Dr. Seuss books."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVHxasNCP9hz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4a91a8b-a68b-4cd8-d044-349d600c2926"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "seuss_dir = \"http://dlsun.github.io/pods/data/drseuss/\"\n",
        "seuss_files = [\n",
        "    \"green_eggs_and_ham.txt\", \"cat_in_the_hat.txt\", \"fox_in_socks.txt\",\n",
        "    \"hop_on_pop.txt\", \"horton_hears_a_who.txt\", \"how_the_grinch_stole_christmas.txt\",\n",
        "    \"oh_the_places_youll_go.txt\", \"one_fish_two_fish.txt\"\n",
        "]\n",
        "\n",
        "docs_seuss = pd.Series()\n",
        "for file in seuss_files:\n",
        "    response = requests.get(seuss_dir + file, \"r\")\n",
        "    docs_seuss[file[:-4]] = response.text\n",
        "\n",
        "docs_seuss"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "green_eggs_and_ham                I am Sam\\n\\nI am Sam\\nSam I am\\n\\nThat Sam-I-a...\n",
              "cat_in_the_hat                    The sun did not shine.\\nIt was too wet to play...\n",
              "fox_in_socks                      Fox\\nSocks\\nBox\\nKnox\\n\\nKnox in box.\\nFox in ...\n",
              "hop_on_pop                        UP PUP Pup is up.\\nCUP PUP Pup in cup.\\nPUP CU...\n",
              "horton_hears_a_who                On the fifteenth of May, in the jungle of Nool...\n",
              "how_the_grinch_stole_christmas    Every Who\\nDown in Whoville\\nLiked Christmas a...\n",
              "oh_the_places_youll_go            Congratulations!\\nToday is your day.\\nYou're o...\n",
              "one_fish_two_fish                 One fish, two fish, red fish, blue fish,\\nBlac...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_-_HcWAP9h3"
      },
      "source": [
        "Suppose, for example, that we want to determine which two Dr. Seuss books are most similar or cluster the books into several types. In order to leverage the methods that we learned in Parts I and II of this book, we have to convert these documents into tabular form. In this lesson, we focus on a particular representation of a document called the _bag of words_.\n",
        "\n",
        "The _bag of words_ representation reduces a document to just the multiset of its words, ignoring grammar and word order. (A _multiset_ is like a set, except that elements are allowed to appear more than once.)\n",
        "\n",
        "So, for example, the **bag of words** representation of \"I am Sam. Sam I am.\" (the first two lines of _Green Eggs and Ham_) would be `{I, I, am, am, Sam, Sam}`. In Python, it is easiest to represent multisets using dictionaries, where the keys are the (unique) words and the values are the counts. So we would represent the above bag of words as `{\"I\": 2, \"am\": 2, \"Sam\": 2}`.\n",
        "\n",
        "Let's convert the Dr. Seuss books to a bag of words representation. To do this, we will use the `Counter` object in the `collections` module of the Python standard library. First, let's see how the `Counter` works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oVrzGuEP9h3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2c4d0a0-b76f-4739-e04b-d1a22290226f"
      },
      "source": [
        "from collections import Counter\n",
        "Counter([\"I\", \"am\", \"Sam\", \"Sam\", \"I\", \"am\"])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'I': 2, 'Sam': 2, 'am': 2})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsOSVRsbP9h7"
      },
      "source": [
        "It takes in a list and returns a dictionary of counts---in other words, the bag of words representation that we want. But to be able to use `Counter`, we have to first convert our document into a list of words. We can do this using the string methods in Pandas, such as `.str.split()`, which splits a string into a list based on some character (which, by default, is whitespace)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn0-18IhP9h8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf027c1c-569e-43b7-e5ae-e26abeeadb1d"
      },
      "source": [
        "docs_seuss.str.split()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "green_eggs_and_ham                [I, am, Sam, I, am, Sam, Sam, I, am, That, Sam...\n",
              "cat_in_the_hat                    [The, sun, did, not, shine., It, was, too, wet...\n",
              "fox_in_socks                      [Fox, Socks, Box, Knox, Knox, in, box., Fox, i...\n",
              "hop_on_pop                        [UP, PUP, Pup, is, up., CUP, PUP, Pup, in, cup...\n",
              "horton_hears_a_who                [On, the, fifteenth, of, May,, in, the, jungle...\n",
              "how_the_grinch_stole_christmas    [Every, Who, Down, in, Whoville, Liked, Christ...\n",
              "oh_the_places_youll_go            [Congratulations!, Today, is, your, day., You'...\n",
              "one_fish_two_fish                 [One, fish,, two, fish,, red, fish,, blue, fis...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86U_cqXUP9h_"
      },
      "source": [
        "There are several problems with this approach:\n",
        "\n",
        "- **It is case-sensitive.**  The words \"PUP\" and \"Pup\" in _Hop on Pop_ are technically different strings and will be treated as different words by the `Counter`.\n",
        "- **There is punctuation.**  For example, in _One Fish, Two Fish_, the words \"fish,\" and \"fish.\" will be treated as separate words.\n",
        "\n",
        "We can **normalize** the text for case by \n",
        "\n",
        "- converting all of the characters to lowercase, using the `.str.lower()` method\n",
        "- stripping punctuation using a regular expression. The regular expression `[^\\w\\s]` tells Python to look for any pattern that is not (`^`) either an alphanumeric character (`\\w`) or whitespace (`\\s`). That is, it will detect any occurrence of punctuation. We will then use the `.str.replace()` method to replace all detected occurrences with whitespace, effectively removing all punctuation from the string.\n",
        "\n",
        "By chaining these commands together, we obtain a list, to which we can apply the `Counter` to obtain the bag of words representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp6l2xERP9iA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a12ee32-bbbb-48e0-dc7f-10e0bf5998ff"
      },
      "source": [
        "words = (\n",
        "    docs_seuss.\n",
        "    str.lower().\n",
        "    str.replace(\"[^\\w\\s]\", \" \").\n",
        "    str.split()\n",
        ")\n",
        "\n",
        "words"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "green_eggs_and_ham                [i, am, sam, i, am, sam, sam, i, am, that, sam...\n",
              "cat_in_the_hat                    [the, sun, did, not, shine, it, was, too, wet,...\n",
              "fox_in_socks                      [fox, socks, box, knox, knox, in, box, fox, in...\n",
              "hop_on_pop                        [up, pup, pup, is, up, cup, pup, pup, in, cup,...\n",
              "horton_hears_a_who                [on, the, fifteenth, of, may, in, the, jungle,...\n",
              "how_the_grinch_stole_christmas    [every, who, down, in, whoville, liked, christ...\n",
              "oh_the_places_youll_go            [congratulations, today, is, your, day, you, r...\n",
              "one_fish_two_fish                 [one, fish, two, fish, red, fish, blue, fish, ...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEQBeIPsP9iD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33d9011c-2baa-4d59-a80e-12c5db9a80d6"
      },
      "source": [
        "words.apply(Counter)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "green_eggs_and_ham                {'i': 84, 'am': 16, 'sam': 19, 'that': 3, 'do'...\n",
              "cat_in_the_hat                    {'the': 97, 'sun': 2, 'did': 10, 'not': 41, 's...\n",
              "fox_in_socks                      {'fox': 17, 'socks': 19, 'box': 7, 'knox': 17,...\n",
              "hop_on_pop                        {'up': 6, 'pup': 8, 'is': 12, 'cup': 4, 'in': ...\n",
              "horton_hears_a_who                {'on': 21, 'the': 97, 'fifteenth': 1, 'of': 39...\n",
              "how_the_grinch_stole_christmas    {'every': 5, 'who': 18, 'down': 10, 'in': 17, ...\n",
              "oh_the_places_youll_go            {'congratulations': 1, 'today': 2, 'is': 7, 'y...\n",
              "one_fish_two_fish                 {'one': 14, 'fish': 12, 'two': 4, 'red': 2, 'b...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LB1DVV7IP9iH"
      },
      "source": [
        "## N-Grams\n",
        "\n",
        "The problem with the bag of words representation is that the ordering of the words is lost. For example, the following sentences have the exact same bag of words representation, but convey different meanings:\n",
        "\n",
        "1. The dog bit her owner.\n",
        "2. Her dog bit the owner.\n",
        "\n",
        "The first sentence has only two actors (the dog and its owner), but the second sentence has three (a woman, her dog, and the owner of something). To better capture the _semantic_ meaning of these two documents, we can use **bigrams** instead of individual words. A **bigram** is simply a pair of consecutive words. The \"bag of bigrams\" of the two sentences above are quite different:\n",
        "\n",
        "1. {\"The dog\", \"dog bit\", \"bit her\", \"her owner\"}\n",
        "2. {\"Her dog\", \"dog bit\", \"bit the\", \"the owner\"}\n",
        "\n",
        "They only share 1 bigram (out of 4) in common, despite sharing the same 5 words.\n",
        "\n",
        "Let's get the bag of bigrams representation for the words above. To generate the bigrams from the list of words, we will use the `zip` function in Python, which takes in two lists and returns a single list of pairs (consisting of one element from each list):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0sw5SnzP9iH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "763141b7-bb74-4fec-c581-4121cdc097d6"
      },
      "source": [
        "list(zip([1, 2, 3], [4, 5, 6]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 4), (2, 5), (3, 6)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAJ_GxeJP9iK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bed893ee-a3f3-47b2-8d0b-a33348a759ec"
      },
      "source": [
        "def get_bigrams(words):\n",
        "    # We need to line up the words as follows:\n",
        "    #   words[0], words[1]\n",
        "    #   words[1], words[2]\n",
        "    #       ... ,  ...\n",
        "    # words[n-1], words[n]\n",
        "    #   words[n]\n",
        "    # The first list is longer, so the last element in the first list is ignored.\n",
        "    return zip(words, words[1:])\n",
        "\n",
        "words.apply(get_bigrams).apply(Counter)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "green_eggs_and_ham                {('i', 'am'): 16, ('am', 'sam'): 2, ('sam', 'i...\n",
              "cat_in_the_hat                    {('the', 'sun'): 2, ('sun', 'did'): 1, ('did',...\n",
              "fox_in_socks                      {('fox', 'socks'): 1, ('socks', 'box'): 1, ('b...\n",
              "hop_on_pop                        {('up', 'pup'): 1, ('pup', 'pup'): 2, ('pup', ...\n",
              "horton_hears_a_who                {('on', 'the'): 5, ('the', 'fifteenth'): 1, ('...\n",
              "how_the_grinch_stole_christmas    {('every', 'who'): 4, ('who', 'down'): 4, ('do...\n",
              "oh_the_places_youll_go            {('congratulations', 'today'): 1, ('today', 'i...\n",
              "one_fish_two_fish                 {('one', 'fish'): 1, ('fish', 'two'): 1, ('two...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xof8u3gHP9iO"
      },
      "source": [
        "Instead of taking 2 words at a time, we could take 3, 4, or, in general, $n$ words. \n",
        "A tuple of $n$ consecutive words is called an $n$-gram, and we can convert any document to a \"bag of $n$-grams\" representation. \n",
        "\n",
        "The larger $n$ is, the better the representation will capture the meaning of a document. But if $n$ is so large that hardly any $n$-gram occurs more than once, then we will not learn much from this representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8itCO13P9iP"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah-BZi2BP9iQ"
      },
      "source": [
        "1\\. Read in the OKCupid data set (`https://dlsun.github.io/pods/data/okcupid.csv`). Convert the users' responses to `essay0` (\"self summary\") into a bag of words representation. What word appears most often?\n",
        "\n",
        "(_Hint:_ Test your code on the first 100 users before testing it on the entire data set.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://dlsun.github.io/pods/data/okcupid.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "EFzT8gehcOx_",
        "outputId": "0c5561d7-b52e-4b33-eb46-c83cc6998c07"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age body_type               diet    drinks      drugs  \\\n",
              "0   31       NaN  mostly vegetarian  socially  sometimes   \n",
              "1   25   average                NaN  socially        NaN   \n",
              "2   43     curvy                NaN    rarely      never   \n",
              "3   31   average                NaN  socially      never   \n",
              "4   34       NaN                NaN  socially        NaN   \n",
              "\n",
              "                           education  \\\n",
              "0  graduated from college/university   \n",
              "1      working on college/university   \n",
              "2     graduated from masters program   \n",
              "3                                NaN   \n",
              "4        graduated from ph.d program   \n",
              "\n",
              "                                              essay0  \\\n",
              "0  75% nice, 45% shy, 80% stubborn, 100% charming...   \n",
              "1  i like trees, spending long periods of time co...   \n",
              "2                                                NaN   \n",
              "3  i am a seeker of laughs ,music ,magick good pe...   \n",
              "4  i've just moved here from london after finishi...   \n",
              "\n",
              "                                              essay1  \\\n",
              "0                         i'm a new nurse. it rules.   \n",
              "1  studying landscape horticulture, beekeeping, g...   \n",
              "2                                                NaN   \n",
              "3  i strive to live life to the fullest and to tr...   \n",
              "4      i'm doing a postdoc in psychology at stanford   \n",
              "\n",
              "                                              essay2  \\\n",
              "0                multiple-choice questions, dancing.   \n",
              "1            wasting time, making breakfast, nesting   \n",
              "2                                                NaN   \n",
              "3  i am good at my magic and weaving a world of i...   \n",
              "4                                                NaN   \n",
              "\n",
              "                                              essay3  ...  \\\n",
              "0                          it depends on the people.  ...   \n",
              "1                           i have a lot of freckles  ...   \n",
              "2                                                NaN  ...   \n",
              "3  i am guessing y'all would notice my jewelry an...  ...   \n",
              "4                                                NaN  ...   \n",
              "\n",
              "                    location                offspring orientation  \\\n",
              "0  san francisco, california          might want kids         gay   \n",
              "1        oakland, california                      NaN         gay   \n",
              "2  san francisco, california                has a kid    straight   \n",
              "3  san francisco, california  doesn&rsquo;t want kids         gay   \n",
              "4  san francisco, california                      NaN         gay   \n",
              "\n",
              "                      pets                         religion sex  \\\n",
              "0               likes cats                         buddhism   f   \n",
              "1                      NaN                              NaN   m   \n",
              "2  likes dogs and has cats      other and laughing about it   f   \n",
              "3                      NaN  other and very serious about it   m   \n",
              "4                      NaN                              NaN   m   \n",
              "\n",
              "                                            sign          smokes  height  \\\n",
              "0       taurus and it&rsquo;s fun to think about              no    67.0   \n",
              "1  sagittarius and it&rsquo;s fun to think about              no    66.0   \n",
              "2          leo and it&rsquo;s fun to think about  trying to quit    65.0   \n",
              "3    capricorn and it&rsquo;s fun to think about  trying to quit    70.0   \n",
              "4             cancer but it doesn&rsquo;t matter             NaN    71.0   \n",
              "\n",
              "   status  \n",
              "0  single  \n",
              "1  single  \n",
              "2  single  \n",
              "3  single  \n",
              "4  single  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10944b6a-6702-4eca-b350-4ab7dc2eb07a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>body_type</th>\n",
              "      <th>diet</th>\n",
              "      <th>drinks</th>\n",
              "      <th>drugs</th>\n",
              "      <th>education</th>\n",
              "      <th>essay0</th>\n",
              "      <th>essay1</th>\n",
              "      <th>essay2</th>\n",
              "      <th>essay3</th>\n",
              "      <th>...</th>\n",
              "      <th>location</th>\n",
              "      <th>offspring</th>\n",
              "      <th>orientation</th>\n",
              "      <th>pets</th>\n",
              "      <th>religion</th>\n",
              "      <th>sex</th>\n",
              "      <th>sign</th>\n",
              "      <th>smokes</th>\n",
              "      <th>height</th>\n",
              "      <th>status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>mostly vegetarian</td>\n",
              "      <td>socially</td>\n",
              "      <td>sometimes</td>\n",
              "      <td>graduated from college/university</td>\n",
              "      <td>75% nice, 45% shy, 80% stubborn, 100% charming...</td>\n",
              "      <td>i'm a new nurse. it rules.</td>\n",
              "      <td>multiple-choice questions, dancing.</td>\n",
              "      <td>it depends on the people.</td>\n",
              "      <td>...</td>\n",
              "      <td>san francisco, california</td>\n",
              "      <td>might want kids</td>\n",
              "      <td>gay</td>\n",
              "      <td>likes cats</td>\n",
              "      <td>buddhism</td>\n",
              "      <td>f</td>\n",
              "      <td>taurus and it&amp;rsquo;s fun to think about</td>\n",
              "      <td>no</td>\n",
              "      <td>67.0</td>\n",
              "      <td>single</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25</td>\n",
              "      <td>average</td>\n",
              "      <td>NaN</td>\n",
              "      <td>socially</td>\n",
              "      <td>NaN</td>\n",
              "      <td>working on college/university</td>\n",
              "      <td>i like trees, spending long periods of time co...</td>\n",
              "      <td>studying landscape horticulture, beekeeping, g...</td>\n",
              "      <td>wasting time, making breakfast, nesting</td>\n",
              "      <td>i have a lot of freckles</td>\n",
              "      <td>...</td>\n",
              "      <td>oakland, california</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gay</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>m</td>\n",
              "      <td>sagittarius and it&amp;rsquo;s fun to think about</td>\n",
              "      <td>no</td>\n",
              "      <td>66.0</td>\n",
              "      <td>single</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>43</td>\n",
              "      <td>curvy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>rarely</td>\n",
              "      <td>never</td>\n",
              "      <td>graduated from masters program</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>san francisco, california</td>\n",
              "      <td>has a kid</td>\n",
              "      <td>straight</td>\n",
              "      <td>likes dogs and has cats</td>\n",
              "      <td>other and laughing about it</td>\n",
              "      <td>f</td>\n",
              "      <td>leo and it&amp;rsquo;s fun to think about</td>\n",
              "      <td>trying to quit</td>\n",
              "      <td>65.0</td>\n",
              "      <td>single</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31</td>\n",
              "      <td>average</td>\n",
              "      <td>NaN</td>\n",
              "      <td>socially</td>\n",
              "      <td>never</td>\n",
              "      <td>NaN</td>\n",
              "      <td>i am a seeker of laughs ,music ,magick good pe...</td>\n",
              "      <td>i strive to live life to the fullest and to tr...</td>\n",
              "      <td>i am good at my magic and weaving a world of i...</td>\n",
              "      <td>i am guessing y'all would notice my jewelry an...</td>\n",
              "      <td>...</td>\n",
              "      <td>san francisco, california</td>\n",
              "      <td>doesn&amp;rsquo;t want kids</td>\n",
              "      <td>gay</td>\n",
              "      <td>NaN</td>\n",
              "      <td>other and very serious about it</td>\n",
              "      <td>m</td>\n",
              "      <td>capricorn and it&amp;rsquo;s fun to think about</td>\n",
              "      <td>trying to quit</td>\n",
              "      <td>70.0</td>\n",
              "      <td>single</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>34</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>socially</td>\n",
              "      <td>NaN</td>\n",
              "      <td>graduated from ph.d program</td>\n",
              "      <td>i've just moved here from london after finishi...</td>\n",
              "      <td>i'm doing a postdoc in psychology at stanford</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>san francisco, california</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gay</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>m</td>\n",
              "      <td>cancer but it doesn&amp;rsquo;t matter</td>\n",
              "      <td>NaN</td>\n",
              "      <td>71.0</td>\n",
              "      <td>single</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10944b6a-6702-4eca-b350-4ab7dc2eb07a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10944b6a-6702-4eca-b350-4ab7dc2eb07a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10944b6a-6702-4eca-b350-4ab7dc2eb07a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = (\n",
        "    df['essay0'].str.lower().\n",
        "    str.replace(\"[^\\w\\s]\", \" \").\n",
        "    fillna(' ').\n",
        "    str.split()\n",
        ")\n",
        "\n",
        "words = words.sum()\n",
        "Counter(words).most_common()[0]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEdw_FAOcZPN",
        "outputId": "b8e9f22d-8b06-48a3-82fd-546e5d66e6c8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('i', 22674)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj2oZSscP9iR"
      },
      "source": [
        "2\\. Find the bag of trigrams representation for the Dr. Seuss books. How could you use the bag of trigrams to determine which book is the most linguistically diverse? Which book is it?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(zip(words, words[1:], words[2:]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-S7Xsd9kcrn",
        "outputId": "14cd3ad4-8433-4316-e708-c8bfdd9c3fff"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({('75', 'nice', '45'): 1,\n",
              "         ('nice', '45', 'shy'): 1,\n",
              "         ('45', 'shy', '80'): 1,\n",
              "         ('shy', '80', 'stubborn'): 1,\n",
              "         ('80', 'stubborn', '100'): 1,\n",
              "         ('stubborn', '100', 'charming'): 1,\n",
              "         ('100', 'charming', '25'): 1,\n",
              "         ('charming', '25', 'of'): 1,\n",
              "         ('25', 'of', 'the'): 1,\n",
              "         ('of', 'the', 'time'): 38,\n",
              "         ('the', 'time', 'good'): 2,\n",
              "         ('time', 'good', 'listener'): 1,\n",
              "         ('good', 'listener', 'good'): 1,\n",
              "         ('listener', 'good', 'imagination'): 1,\n",
              "         ('good', 'imagination', 'multitudinous'): 1,\n",
              "         ('imagination', 'multitudinous', 'ish'): 1,\n",
              "         ('multitudinous', 'ish', 'i'): 1,\n",
              "         ('ish', 'i', 'like'): 1,\n",
              "         ('i', 'like', 'trees'): 1,\n",
              "         ('like', 'trees', 'spending'): 1,\n",
              "         ('trees', 'spending', 'long'): 1,\n",
              "         ('spending', 'long', 'periods'): 1,\n",
              "         ('long', 'periods', 'of'): 2,\n",
              "         ('periods', 'of', 'time'): 5,\n",
              "         ('of', 'time', 'cooking'): 1,\n",
              "         ('time', 'cooking', 'delicious'): 1,\n",
              "         ('cooking', 'delicious', 'food'): 1,\n",
              "         ('delicious', 'food', 'and'): 1,\n",
              "         ('food', 'and', 'contemplating'): 1,\n",
              "         ('and', 'contemplating', 'my'): 1,\n",
              "         ('contemplating', 'my', 'place'): 1,\n",
              "         ('my', 'place', 'in'): 4,\n",
              "         ('place', 'in', 'the'): 8,\n",
              "         ('in', 'the', 'world'): 54,\n",
              "         ('the', 'world', 'i'): 36,\n",
              "         ('world', 'i', 'm'): 5,\n",
              "         ('i', 'm', 'in'): 60,\n",
              "         ('m', 'in', 'the'): 13,\n",
              "         ('in', 'the', 'middle'): 12,\n",
              "         ('the', 'middle', 'of'): 9,\n",
              "         ('middle', 'of', 'an'): 1,\n",
              "         ('of', 'an', 'existential'): 1,\n",
              "         ('an', 'existential', 'crisis'): 1,\n",
              "         ('existential', 'crisis', 'i'): 1,\n",
              "         ('crisis', 'i', 'am'): 1,\n",
              "         ('i', 'am', 'a'): 511,\n",
              "         ('am', 'a', 'seeker'): 1,\n",
              "         ('a', 'seeker', 'of'): 3,\n",
              "         ('seeker', 'of', 'laughs'): 1,\n",
              "         ('of', 'laughs', 'music'): 1,\n",
              "         ('laughs', 'music', 'magick'): 1,\n",
              "         ('music', 'magick', 'good'): 1,\n",
              "         ('magick', 'good', 'people'): 1,\n",
              "         ('good', 'people', 'and'): 1,\n",
              "         ('people', 'and', 'good'): 2,\n",
              "         ('and', 'good', 'food'): 6,\n",
              "         ('good', 'food', 'i'): 7,\n",
              "         ('food', 'i', 'love'): 5,\n",
              "         ('i', 'love', 'music'): 28,\n",
              "         ('love', 'music', 'and'): 14,\n",
              "         ('music', 'and', 'going'): 2,\n",
              "         ('and', 'going', 'to'): 26,\n",
              "         ('going', 'to', 'shows'): 10,\n",
              "         ('to', 'shows', 'and'): 5,\n",
              "         ('shows', 'and', 'to'): 1,\n",
              "         ('and', 'to', 'movies'): 1,\n",
              "         ('to', 'movies', 'and'): 4,\n",
              "         ('movies', 'and', 'surrounding'): 1,\n",
              "         ('and', 'surrounding', 'myself'): 2,\n",
              "         ('surrounding', 'myself', 'with'): 7,\n",
              "         ('myself', 'with', 'amazing'): 1,\n",
              "         ('with', 'amazing', 'people'): 5,\n",
              "         ('amazing', 'people', 'i'): 1,\n",
              "         ('people', 'i', 'love'): 19,\n",
              "         ('love', 'music', 'everything'): 1,\n",
              "         ('music', 'everything', 'from'): 1,\n",
              "         ('everything', 'from', 'old'): 1,\n",
              "         ('from', 'old', 'school'): 1,\n",
              "         ('old', 'school', 'punk'): 1,\n",
              "         ('school', 'punk', 'and'): 1,\n",
              "         ('punk', 'and', 'death'): 1,\n",
              "         ('and', 'death', 'rock'): 1,\n",
              "         ('death', 'rock', 'to'): 1,\n",
              "         ('rock', 'to', 'the'): 2,\n",
              "         ('to', 'the', 'blues'): 1,\n",
              "         ('the', 'blues', 'yes'): 1,\n",
              "         ('blues', 'yes', 'music'): 1,\n",
              "         ('yes', 'music', 'and'): 1,\n",
              "         ('music', 'and', 'the'): 1,\n",
              "         ('and', 'the', 'occult'): 1,\n",
              "         ('the', 'occult', 'and'): 1,\n",
              "         ('occult', 'and', 'good'): 1,\n",
              "         ('and', 'good', 'horror'): 1,\n",
              "         ('good', 'horror', 'movies'): 1,\n",
              "         ('horror', 'movies', 'are'): 1,\n",
              "         ('movies', 'are', 'my'): 2,\n",
              "         ('are', 'my', 'passions'): 1,\n",
              "         ('my', 'passions', 'and'): 1,\n",
              "         ('passions', 'and', 'i'): 1,\n",
              "         ('and', 'i', 'am'): 95,\n",
              "         ('i', 'am', 'the'): 46,\n",
              "         ('am', 'the', 'emcee'): 1,\n",
              "         ('the', 'emcee', 'for'): 1,\n",
              "         ('emcee', 'for', 'a'): 1,\n",
              "         ('for', 'a', 'local'): 1,\n",
              "         ('a', 'local', 'drag'): 1,\n",
              "         ('local', 'drag', 'cabaret'): 1,\n",
              "         ('drag', 'cabaret', 'show'): 1,\n",
              "         ('cabaret', 'show', 'i'): 1,\n",
              "         ('show', 'i', 've'): 1,\n",
              "         ('i', 've', 'just'): 7,\n",
              "         ('ve', 'just', 'moved'): 2,\n",
              "         ('just', 'moved', 'here'): 7,\n",
              "         ('moved', 'here', 'from'): 10,\n",
              "         ('here', 'from', 'london'): 1,\n",
              "         ('from', 'london', 'after'): 1,\n",
              "         ('london', 'after', 'finishing'): 1,\n",
              "         ('after', 'finishing', 'my'): 1,\n",
              "         ('finishing', 'my', 'phd'): 1,\n",
              "         ('my', 'phd', 'i'): 1,\n",
              "         ('phd', 'i', 'have'): 1,\n",
              "         ('i', 'have', 'lots'): 6,\n",
              "         ('have', 'lots', 'of'): 11,\n",
              "         ('lots', 'of', 'great'): 1,\n",
              "         ('of', 'great', 'friends'): 1,\n",
              "         ('great', 'friends', 'and'): 8,\n",
              "         ('friends', 'and', 'people'): 1,\n",
              "         ('and', 'people', 'in'): 3,\n",
              "         ('people', 'in', 'my'): 9,\n",
              "         ('in', 'my', 'life'): 115,\n",
              "         ('my', 'life', 'i'): 69,\n",
              "         ('life', 'i', 'enjoy'): 5,\n",
              "         ('i', 'enjoy', 'most'): 6,\n",
              "         ('enjoy', 'most', 'sports'): 1,\n",
              "         ('most', 'sports', 'playing'): 1,\n",
              "         ('sports', 'playing', 'more'): 1,\n",
              "         ('playing', 'more', 'than'): 1,\n",
              "         ('more', 'than', 'watching'): 2,\n",
              "         ('than', 'watching', 'i'): 1,\n",
              "         ('watching', 'i', 'like'): 1,\n",
              "         ('i', 'like', 'a'): 35,\n",
              "         ('like', 'a', 'good'): 10,\n",
              "         ('a', 'good', 'book'): 12,\n",
              "         ('good', 'book', 'travel'): 1,\n",
              "         ('book', 'travel', 'good'): 1,\n",
              "         ('travel', 'good', 'food'): 1,\n",
              "         ('good', 'food', 'and'): 14,\n",
              "         ('food', 'and', 'love'): 1,\n",
              "         ('and', 'love', 'to'): 48,\n",
              "         ('love', 'to', 'have'): 24,\n",
              "         ('to', 'have', 'fun'): 52,\n",
              "         ('have', 'fun', 'my'): 3,\n",
              "         ('fun', 'my', 'name'): 1,\n",
              "         ('my', 'name', 'is'): 77,\n",
              "         ('name', 'is', 'karyn'): 1,\n",
              "         ('is', 'karyn', 'i'): 1,\n",
              "         ('karyn', 'i', 'am'): 1,\n",
              "         ('i', 'am', 'fun'): 20,\n",
              "         ('am', 'fun', 'loving'): 4,\n",
              "         ('fun', 'loving', 'outgoing'): 2,\n",
              "         ('loving', 'outgoing', 'and'): 1,\n",
              "         ('outgoing', 'and', 'very'): 2,\n",
              "         ('and', 'very', 'energetic'): 1,\n",
              "         ('very', 'energetic', 'i'): 1,\n",
              "         ('energetic', 'i', 'enjoy'): 1,\n",
              "         ('i', 'enjoy', 'long'): 3,\n",
              "         ('enjoy', 'long', 'walks'): 4,\n",
              "         ('long', 'walks', 'on'): 13,\n",
              "         ('walks', 'on', 'the'): 18,\n",
              "         ('on', 'the', 'beach'): 26,\n",
              "         ('the', 'beach', 'having'): 1,\n",
              "         ('beach', 'having', 'fun'): 1,\n",
              "         ('having', 'fun', 'and'): 7,\n",
              "         ('fun', 'and', 'spending'): 1,\n",
              "         ('and', 'spending', 'quality'): 1,\n",
              "         ('spending', 'quality', 'time'): 3,\n",
              "         ('quality', 'time', 'with'): 6,\n",
              "         ('time', 'with', 'my'): 22,\n",
              "         ('with', 'my', 'family'): 20,\n",
              "         ('my', 'family', 'i'): 13,\n",
              "         ('family', 'i', 'would'): 1,\n",
              "         ('i', 'would', 'like'): 66,\n",
              "         ('would', 'like', 'to'): 94,\n",
              "         ('like', 'to', 'have'): 43,\n",
              "         ('to', 'have', 'someone'): 4,\n",
              "         ('have', 'someone', 'to'): 3,\n",
              "         ('someone', 'to', 'cuddle'): 2,\n",
              "         ('to', 'cuddle', 'with'): 2,\n",
              "         ('cuddle', 'with', 'and'): 1,\n",
              "         ('with', 'and', 'watch'): 2,\n",
              "         ('and', 'watch', 'movies'): 1,\n",
              "         ('watch', 'movies', 'or'): 1,\n",
              "         ('movies', 'or', 'just'): 3,\n",
              "         ('or', 'just', 'hang'): 2,\n",
              "         ('just', 'hang', 'out'): 4,\n",
              "         ('hang', 'out', 'with'): 39,\n",
              "         ('out', 'with', 'if'): 1,\n",
              "         ('with', 'if', 'your'): 1,\n",
              "         ('if', 'your', 'interested'): 1,\n",
              "         ('your', 'interested', 'message'): 1,\n",
              "         ('interested', 'message', 'me'): 3,\n",
              "         ('message', 'me', 'east'): 1,\n",
              "         ('me', 'east', 'coast'): 1,\n",
              "         ('east', 'coast', 'transplant'): 7,\n",
              "         ('coast', 'transplant', 'moved'): 1,\n",
              "         ('transplant', 'moved', '2'): 1,\n",
              "         ('moved', '2', 'sf'): 1,\n",
              "         ('2', 'sf', 'a'): 1,\n",
              "         ('sf', 'a', 'month'): 1,\n",
              "         ('a', 'month', 'ago'): 3,\n",
              "         ('month', 'ago', 'and'): 2,\n",
              "         ('ago', 'and', 'absolutely'): 2,\n",
              "         ('and', 'absolutely', 'love'): 5,\n",
              "         ('absolutely', 'love', 'it'): 3,\n",
              "         ('love', 'it', 'here'): 17,\n",
              "         ('it', 'here', 'it'): 1,\n",
              "         ('here', 'it', 's'): 6,\n",
              "         ('it', 's', 'so'): 9,\n",
              "         ('s', 'so', 'much'): 6,\n",
              "         ('so', 'much', 'more'): 16,\n",
              "         ('much', 'more', 'laid'): 1,\n",
              "         ('more', 'laid', 'back'): 1,\n",
              "         ('laid', 'back', 'which'): 1,\n",
              "         ('back', 'which', 'is'): 1,\n",
              "         ('which', 'is', 'more'): 1,\n",
              "         ('is', 'more', 'my'): 2,\n",
              "         ('more', 'my', 'style'): 1,\n",
              "         ('my', 'style', 'i'): 1,\n",
              "         ('style', 'i', 'm'): 1,\n",
              "         ('i', 'm', 'all'): 12,\n",
              "         ('m', 'all', 'about'): 8,\n",
              "         ('all', 'about', 'living'): 1,\n",
              "         ('about', 'living', 'laughing'): 1,\n",
              "         ('living', 'laughing', 'and'): 1,\n",
              "         ('laughing', 'and', 'having'): 2,\n",
              "         ('and', 'having', 'a'): 11,\n",
              "         ('having', 'a', 'blast'): 5,\n",
              "         ('a', 'blast', 'doing'): 1,\n",
              "         ('blast', 'doing', 'it'): 1,\n",
              "         ('doing', 'it', 'stay'): 1,\n",
              "         ('it', 'stay', 'in'): 1,\n",
              "         ('stay', 'in', 'shape'): 3,\n",
              "         ('in', 'shape', 'played'): 1,\n",
              "         ('shape', 'played', 'sports'): 1,\n",
              "         ('played', 'sports', 'all'): 2,\n",
              "         ('sports', 'all', 'my'): 2,\n",
              "         ('all', 'my', 'life'): 6,\n",
              "         ('my', 'life', 'and'): 43,\n",
              "         ('life', 'and', 'love'): 3,\n",
              "         ('and', 'love', 'being'): 5,\n",
              "         ('love', 'being', 'outdoors'): 14,\n",
              "         ('being', 'outdoors', 'life'): 1,\n",
              "         ('outdoors', 'life', 's'): 1,\n",
              "         ('life', 's', 'short'): 2,\n",
              "         ('s', 'short', 'i'): 1,\n",
              "         ('short', 'i', 'll'): 1,\n",
              "         ('i', 'll', 'sleep'): 1,\n",
              "         ('ll', 'sleep', 'when'): 1,\n",
              "         ('sleep', 'when', 'i'): 1,\n",
              "         ('when', 'i', 'm'): 80,\n",
              "         ('i', 'm', 'dead'): 1,\n",
              "         ('m', 'dead', 'new'): 1,\n",
              "         ('dead', 'new', 'to'): 1,\n",
              "         ('new', 'to', 'the'): 19,\n",
              "         ('to', 'the', 'city'): 16,\n",
              "         ('the', 'city', 'so'): 2,\n",
              "         ('city', 'so', 'i'): 2,\n",
              "         ('so', 'i', 'figured'): 4,\n",
              "         ('i', 'figured', 'i'): 4,\n",
              "         ('figured', 'i', 'd'): 4,\n",
              "         ('i', 'd', 'shake'): 1,\n",
              "         ('d', 'shake', 'the'): 1,\n",
              "         ('shake', 'the', 'dice'): 1,\n",
              "         ('the', 'dice', 'and'): 1,\n",
              "         ('dice', 'and', 'see'): 1,\n",
              "         ('and', 'see', 'what'): 16,\n",
              "         ('see', 'what', 'happens'): 8,\n",
              "         ('what', 'happens', 'i'): 4,\n",
              "         ('happens', 'i', 'am'): 2,\n",
              "         ('am', 'a', 'beautiful'): 2,\n",
              "         ('a', 'beautiful', 'fun'): 1,\n",
              "         ('beautiful', 'fun', 'aware'): 1,\n",
              "         ('fun', 'aware', 'compassionate'): 1,\n",
              "         ('aware', 'compassionate', 'free'): 1,\n",
              "         ('compassionate', 'free', 'spirit'): 1,\n",
              "         ('free', 'spirit', 'br'): 1,\n",
              "         ('spirit', 'br', 'br'): 1,\n",
              "         ('br', 'br', 'i'): 2268,\n",
              "         ('br', 'i', 'once'): 10,\n",
              "         ('i', 'once', 'tried'): 2,\n",
              "         ('once', 'tried', 'out'): 1,\n",
              "         ('tried', 'out', 'dating'): 1,\n",
              "         ('out', 'dating', 'an'): 1,\n",
              "         ('dating', 'an', 'atheist'): 1,\n",
              "         ('an', 'atheist', 'thank'): 1,\n",
              "         ('atheist', 'thank', 'god'): 1,\n",
              "         ('thank', 'god', 'for'): 1,\n",
              "         ('god', 'for', 'that'): 1,\n",
              "         ('for', 'that', 'pun'): 1,\n",
              "         ('that', 'pun', 'intended'): 1,\n",
              "         ('pun', 'intended', 'this'): 1,\n",
              "         ('intended', 'this', 'helped'): 1,\n",
              "         ('this', 'helped', 'me'): 1,\n",
              "         ('helped', 'me', 'clarify'): 1,\n",
              "         ('me', 'clarify', 'what'): 1,\n",
              "         ('clarify', 'what', 'i'): 1,\n",
              "         ('what', 'i', 'want'): 40,\n",
              "         ('i', 'want', 'in'): 4,\n",
              "         ('want', 'in', 'a'): 1,\n",
              "         ('in', 'a', 'relationship'): 27,\n",
              "         ('a', 'relationship', 'shared'): 1,\n",
              "         ('relationship', 'shared', 'relationship'): 1,\n",
              "         ('shared', 'relationship', 'with'): 1,\n",
              "         ('relationship', 'with', 'a'): 9,\n",
              "         ('with', 'a', 'force'): 1,\n",
              "         ('a', 'force', 'power'): 1,\n",
              "         ('force', 'power', 'with'): 1,\n",
              "         ('power', 'with', 'and'): 1,\n",
              "         ('with', 'and', 'beyond'): 2,\n",
              "         ('and', 'beyond', 'oneself'): 1,\n",
              "         ('beyond', 'oneself', 'call'): 1,\n",
              "         ('oneself', 'call', 'this'): 1,\n",
              "         ('call', 'this', 'spirit'): 1,\n",
              "         ('this', 'spirit', 'god'): 1,\n",
              "         ('spirit', 'god', 'creator'): 1,\n",
              "         ('god', 'creator', 'whatever'): 1,\n",
              "         ('creator', 'whatever', 'it'): 1,\n",
              "         ('whatever', 'it', 'occurs'): 1,\n",
              "         ('it', 'occurs', 'to'): 1,\n",
              "         ('occurs', 'to', 'me'): 1,\n",
              "         ('to', 'me', 'that'): 11,\n",
              "         ('me', 'that', 'this'): 1,\n",
              "         ('that', 'this', 'shrinks'): 1,\n",
              "         ('this', 'shrinks', 'the'): 1,\n",
              "         ('shrinks', 'the', 'dating'): 1,\n",
              "         ('the', 'dating', 'pool'): 1,\n",
              "         ('dating', 'pool', 'considerably'): 1,\n",
              "         ('pool', 'considerably', 'br'): 1,\n",
              "         ('considerably', 'br', 'br'): 1,\n",
              "         ('br', 'i', 'have'): 159,\n",
              "         ('i', 'have', 'a'): 370,\n",
              "         ('have', 'a', 'deep'): 6,\n",
              "         ('a', 'deep', 'connection'): 4,\n",
              "         ('deep', 'connection', 'to'): 1,\n",
              "         ('connection', 'to', 'nature'): 1,\n",
              "         ('to', 'nature', 'love'): 1,\n",
              "         ('nature', 'love', 'to'): 1,\n",
              "         ('love', 'to', 'be'): 31,\n",
              "         ('to', 'be', 'in'): 31,\n",
              "         ('be', 'in', 'it'): 1,\n",
              "         ('in', 'it', 'hiking'): 1,\n",
              "         ('it', 'hiking', 'permaculture'): 1,\n",
              "         ('hiking', 'permaculture', 'being'): 1,\n",
              "         ('permaculture', 'being', 'i'): 1,\n",
              "         ('being', 'i', 'have'): 1,\n",
              "         ('i', 'have', 'dedicated'): 1,\n",
              "         ('have', 'dedicated', 'a'): 1,\n",
              "         ('dedicated', 'a', 'big'): 1,\n",
              "         ('a', 'big', 'part'): 14,\n",
              "         ('big', 'part', 'of'): 12,\n",
              "         ('part', 'of', 'my'): 38,\n",
              "         ('of', 'my', 'life'): 96,\n",
              "         ('my', 'life', 'to'): 10,\n",
              "         ('life', 'to', 'having'): 1,\n",
              "         ('to', 'having', 'a'): 1,\n",
              "         ('having', 'a', 'more'): 1,\n",
              "         ('a', 'more', 'conscious'): 1,\n",
              "         ('more', 'conscious', 'and'): 1,\n",
              "         ('conscious', 'and', 'co'): 1,\n",
              "         ('and', 'co', 'creative'): 1,\n",
              "         ('co', 'creative', 'relationship'): 1,\n",
              "         ('creative', 'relationship', 'to'): 1,\n",
              "         ('relationship', 'to', 'nature'): 1,\n",
              "         ('to', 'nature', 'this'): 1,\n",
              "         ('nature', 'this', 'includes'): 1,\n",
              "         ('this', 'includes', 'a'): 1,\n",
              "         ('includes', 'a', 'degree'): 1,\n",
              "         ('a', 'degree', 'in'): 6,\n",
              "         ('degree', 'in', 'sustainability'): 1,\n",
              "         ('in', 'sustainability', 'consciousness'): 1,\n",
              "         ('sustainability', 'consciousness', 'healing'): 1,\n",
              "         ('consciousness', 'healing', 'and'): 1,\n",
              "         ('healing', 'and', 'ecology'): 1,\n",
              "         ('and', 'ecology', 'six'): 1,\n",
              "         ('ecology', 'six', 'months'): 1,\n",
              "         ('six', 'months', 'of'): 1,\n",
              "         ('months', 'of', 'permaculture'): 1,\n",
              "         ('of', 'permaculture', 'and'): 1,\n",
              "         ('permaculture', 'and', 'ecovillage'): 1,\n",
              "         ('and', 'ecovillage', 'training'): 1,\n",
              "         ('ecovillage', 'training', 'giving'): 1,\n",
              "         ('training', 'giving', 'up'): 1,\n",
              "         ('giving', 'up', 'my'): 1,\n",
              "         ('up', 'my', 'cush'): 1,\n",
              "         ('my', 'cush', 'life'): 1,\n",
              "         ('cush', 'life', 'for'): 1,\n",
              "         ('life', 'for', 'an'): 1,\n",
              "         ('for', 'an', 'adventure'): 10,\n",
              "         ('an', 'adventure', 'of'): 2,\n",
              "         ('adventure', 'of', 'woofing'): 1,\n",
              "         ('of', 'woofing', 'on'): 1,\n",
              "         ('woofing', 'on', 'farms'): 1,\n",
              "         ('on', 'farms', 'and'): 1,\n",
              "         ('farms', 'and', 'permaculture'): 1,\n",
              "         ('and', 'permaculture', 'sites'): 1,\n",
              "         ('permaculture', 'sites', 'ok'): 1,\n",
              "         ('sites', 'ok', 'it'): 1,\n",
              "         ('ok', 'it', 'was'): 1,\n",
              "         ('it', 'was', 'in'): 2,\n",
              "         ('was', 'in', 'hawaii'): 1,\n",
              "         ('in', 'hawaii', 'so'): 1,\n",
              "         ('hawaii', 'so', 'it'): 1,\n",
              "         ('so', 'it', 'was'): 1,\n",
              "         ('it', 'was', 'pretty'): 4,\n",
              "         ('was', 'pretty', 'lush'): 1,\n",
              "         ('pretty', 'lush', 'br'): 1,\n",
              "         ('lush', 'br', 'br'): 1,\n",
              "         ('br', 'i', 'had'): 5,\n",
              "         ('i', 'had', 'put'): 1,\n",
              "         ('had', 'put', 'aside'): 1,\n",
              "         ('put', 'aside', 'my'): 1,\n",
              "         ('aside', 'my', 'quest'): 1,\n",
              "         ('my', 'quest', 'to'): 1,\n",
              "         ('quest', 'to', 'live'): 1,\n",
              "         ('to', 'live', 'in'): 26,\n",
              "         ('live', 'in', 'harmony'): 2,\n",
              "         ('in', 'harmony', 'with'): 2,\n",
              "         ('harmony', 'with', 'nature'): 2,\n",
              "         ('with', 'nature', 'for'): 1,\n",
              "         ('nature', 'for', 'a'): 1,\n",
              "         ('for', 'a', 'self'): 2,\n",
              "         ('a', 'self', 'development'): 1,\n",
              "         ('self', 'development', 'school'): 1,\n",
              "         ('development', 'school', 'here'): 1,\n",
              "         ('school', 'here', 'in'): 2,\n",
              "         ('here', 'in', 'california'): 3,\n",
              "         ('in', 'california', 'that'): 1,\n",
              "         ('california', 'that', 'has'): 1,\n",
              "         ('that', 'has', 'brought'): 1,\n",
              "         ('has', 'brought', 'me'): 1,\n",
              "         ('brought', 'me', 'to'): 2,\n",
              "         ('me', 'to', 'greater'): 1,\n",
              "         ('to', 'greater', 'and'): 1,\n",
              "         ('greater', 'and', 'greater'): 1,\n",
              "         ('and', 'greater', 'awareness'): 1,\n",
              "         ('greater', 'awareness', 'of'): 1,\n",
              "         ('awareness', 'of', 'my'): 1,\n",
              "         ('of', 'my', 'path'): 1,\n",
              "         ('my', 'path', 'and'): 2,\n",
              "         ('path', 'and', 'helped'): 1,\n",
              "         ('and', 'helped', 'me'): 2,\n",
              "         ('helped', 'me', 'clear'): 1,\n",
              "         ('me', 'clear', 'so'): 1,\n",
              "         ('clear', 'so', 'many'): 1,\n",
              "         ('so', 'many', 'previous'): 1,\n",
              "         ('many', 'previous', 'blocks'): 1,\n",
              "         ('previous', 'blocks', 'i'): 1,\n",
              "         ('blocks', 'i', 'realized'): 1,\n",
              "         ('i', 'realized', 'through'): 1,\n",
              "         ('realized', 'through', 'my'): 1,\n",
              "         ('through', 'my', 'trials'): 1,\n",
              "         ('my', 'trials', 'living'): 1,\n",
              "         ('trials', 'living', 'in'): 1,\n",
              "         ('living', 'in', 'community'): 2,\n",
              "         ('in', 'community', 'that'): 1,\n",
              "         ('community', 'that', 'living'): 1,\n",
              "         ('that', 'living', 'in'): 1,\n",
              "         ('living', 'in', 'balance'): 1,\n",
              "         ('in', 'balance', 'is'): 1,\n",
              "         ('balance', 'is', 'first'): 1,\n",
              "         ('is', 'first', 'and'): 1,\n",
              "         ('first', 'and', 'foremost'): 5,\n",
              "         ('and', 'foremost', 'an'): 1,\n",
              "         ('foremost', 'an', 'inside'): 1,\n",
              "         ('an', 'inside', 'job'): 1,\n",
              "         ('inside', 'job', 'br'): 1,\n",
              "         ('job', 'br', 'br'): 3,\n",
              "         ('br', 'i', 'still'): 4,\n",
              "         ('i', 'still', 'aspire'): 1,\n",
              "         ('still', 'aspire', 'and'): 1,\n",
              "         ('aspire', 'and', 'intend'): 1,\n",
              "         ('and', 'intend', 'to'): 1,\n",
              "         ('intend', 'to', 'live'): 1,\n",
              "         ('with', 'nature', 'and'): 2,\n",
              "         ('nature', 'and', 'i'): 1,\n",
              "         ('i', 'am', 'visioning'): 1,\n",
              "         ('am', 'visioning', 'my'): 1,\n",
              "         ('visioning', 'my', 'steps'): 1,\n",
              "         ('my', 'steps', 'towards'): 1,\n",
              "         ('steps', 'towards', 'that'): 1,\n",
              "         ('towards', 'that', 'now'): 1,\n",
              "         ('that', 'now', 'i'): 3,\n",
              "         ('now', 'i', 'see'): 1,\n",
              "         ('i', 'see', 'living'): 1,\n",
              "         ('see', 'living', 'a'): 1,\n",
              "         ('living', 'a', 'simple'): 1,\n",
              "         ('a', 'simple', 'life'): 3,\n",
              "         ('simple', 'life', 'gardens'): 1,\n",
              "         ('life', 'gardens', 'water'): 1,\n",
              "         ('gardens', 'water', 'catchment'): 1,\n",
              "         ('water', 'catchment', 'natural'): 1,\n",
              "         ('catchment', 'natural', 'buildings'): 1,\n",
              "         ('natural', 'buildings', 'all'): 1,\n",
              "         ('buildings', 'all', 'of'): 1,\n",
              "         ('all', 'of', 'that'): 3,\n",
              "         ('of', 'that', 'with'): 1,\n",
              "         ('that', 'with', 'beauty'): 1,\n",
              "         ('with', 'beauty', 'reverence'): 1,\n",
              "         ('beauty', 'reverence', 'awareness'): 1,\n",
              "         ('reverence', 'awareness', 'and'): 1,\n",
              "         ('awareness', 'and', 'connection'): 1,\n",
              "         ('and', 'connection', 'woven'): 1,\n",
              "         ('connection', 'woven', 'throuighout'): 1,\n",
              "         ('woven', 'throuighout', 'hmmmm'): 1,\n",
              "         ('throuighout', 'hmmmm', 'i'): 1,\n",
              "         ('hmmmm', 'i', 'grew'): 1,\n",
              "         ('i', 'grew', 'up'): 146,\n",
              "         ('grew', 'up', 'in'): 125,\n",
              "         ('up', 'in', 'southern'): 4,\n",
              "         ('in', 'southern', 'california'): 11,\n",
              "         ('southern', 'california', 'i'): 4,\n",
              "         ('california', 'i', 'love'): 4,\n",
              "         ('i', 'love', 'the'): 99,\n",
              "         ('love', 'the', 'beach'): 3,\n",
              "         ('the', 'beach', 'i'): 11,\n",
              "         ('beach', 'i', 'love'): 3,\n",
              "         ('love', 'the', 'water'): 2,\n",
              "         ('the', 'water', 'i'): 2,\n",
              "         ('water', 'i', 'love'): 2,\n",
              "         ('i', 'love', 'to'): 334,\n",
              "         ('to', 'be', 'outdoors'): 5,\n",
              "         ('be', 'outdoors', 'on'): 1,\n",
              "         ('outdoors', 'on', 'a'): 1,\n",
              "         ('on', 'a', 'sunny'): 8,\n",
              "         ('a', 'sunny', 'day'): 6,\n",
              "         ('sunny', 'day', 'spf'): 1,\n",
              "         ('day', 'spf', 'infinity'): 1,\n",
              "         ('spf', 'infinity', 'i'): 1,\n",
              "         ('infinity', 'i', 'enjoy'): 1,\n",
              "         ('i', 'enjoy', 'healthy'): 1,\n",
              "         ('enjoy', 'healthy', 'competition'): 1,\n",
              "         ('healthy', 'competition', 'be'): 1,\n",
              "         ('competition', 'be', 'it'): 1,\n",
              "         ('be', 'it', 'trivia'): 1,\n",
              "         ('it', 'trivia', 'sports'): 1,\n",
              "         ('trivia', 'sports', 'rock'): 1,\n",
              "         ('sports', 'rock', 'paper'): 1,\n",
              "         ('rock', 'paper', 'scissors'): 1,\n",
              "         ('paper', 'scissors', 'i'): 1,\n",
              "         ('scissors', 'i', 'am'): 1,\n",
              "         ('i', 'am', 'apt'): 1,\n",
              "         ('am', 'apt', 'to'): 2,\n",
              "         ('apt', 'to', 'quote'): 1,\n",
              "         ('to', 'quote', 'movies'): 2,\n",
              "         ('quote', 'movies', 'at'): 1,\n",
              "         ('movies', 'at', 'length'): 1,\n",
              "         ('at', 'length', 'generally'): 1,\n",
              "         ('length', 'generally', 'until'): 1,\n",
              "         ('generally', 'until', 'someone'): 1,\n",
              "         ('until', 'someone', 'either'): 1,\n",
              "         ('someone', 'either', 'names'): 1,\n",
              "         ('either', 'names', 'the'): 1,\n",
              "         ('names', 'the', 'movie'): 1,\n",
              "         ('the', 'movie', 'or'): 1,\n",
              "         ('movie', 'or', 'strikes'): 1,\n",
              "         ('or', 'strikes', 'me'): 1,\n",
              "         ('strikes', 'me', 'i'): 1,\n",
              "         ('me', 'i', 'can'): 7,\n",
              "         ('i', 'can', 'be'): 101,\n",
              "         ('can', 'be', 'sarcastic'): 2,\n",
              "         ('be', 'sarcastic', 'i'): 2,\n",
              "         ('sarcastic', 'i', 'can'): 2,\n",
              "         ('i', 'can', 'dish'): 2,\n",
              "         ('can', 'dish', 'it'): 2,\n",
              "         ('dish', 'it', 'out'): 1,\n",
              "         ('it', 'out', 'and'): 4,\n",
              "         ('out', 'and', 'am'): 2,\n",
              "         ('and', 'am', 'willing'): 3,\n",
              "         ('am', 'willing', 'to'): 10,\n",
              "         ('willing', 'to', 'take'): 6,\n",
              "         ('to', 'take', 'it'): 4,\n",
              "         ('take', 'it', 'there'): 1,\n",
              "         ('it', 'there', 'isn'): 1,\n",
              "         ('there', 'isn', 't'): 5,\n",
              "         ('isn', 't', 'much'): 1,\n",
              "         ('t', 'much', 'in'): 1,\n",
              "         ('much', 'in', 'life'): 3,\n",
              "         ('in', 'life', 'that'): 5,\n",
              "         ('life', 'that', 'is'): 1,\n",
              "         ('that', 'is', 'so'): 5,\n",
              "         ('is', 'so', 'serious'): 1,\n",
              "         ('so', 'serious', 'that'): 1,\n",
              "         ('serious', 'that', 'it'): 1,\n",
              "         ('that', 'it', 'can'): 1,\n",
              "         ('it', 'can', 't'): 3,\n",
              "         ('can', 't', 'be'): 12,\n",
              "         ('t', 'be', 'joked'): 1,\n",
              "         ('be', 'joked', 'about'): 1,\n",
              "         ('joked', 'about', 'i'): 2,\n",
              "         ('about', 'i', 'm'): 3,\n",
              "         ('i', 'm', '6'): 2,\n",
              "         ('m', '6', '10'): 1,\n",
              "         ('6', '10', 'so'): 1,\n",
              "         ('10', 'so', 'yes'): 1,\n",
              "         ('so', 'yes', 'i'): 3,\n",
              "         ('yes', 'i', 'did'): 1,\n",
              "         ('i', 'did', 'play'): 1,\n",
              "         ('did', 'play', 'basketball'): 1,\n",
              "         ('play', 'basketball', 'but'): 1,\n",
              "         ('basketball', 'but', 'like'): 1,\n",
              "         ('but', 'like', 'i'): 3,\n",
              "         ('like', 'i', 'said'): 4,\n",
              "         ('i', 'said', 'i'): 6,\n",
              "         ('said', 'i', 'love'): 2,\n",
              "         ('the', 'water', 'it'): 1,\n",
              "         ('water', 'it', 'is'): 1,\n",
              "         ('it', 'is', 'my'): 8,\n",
              "         ('is', 'my', 'second'): 2,\n",
              "         ('my', 'second', 'home'): 1,\n",
              "         ('second', 'home', 'and'): 2,\n",
              "         ('home', 'and', 'swimming'): 1,\n",
              "         ('and', 'swimming', 'water'): 1,\n",
              "         ('swimming', 'water', 'sports'): 1,\n",
              "         ('water', 'sports', 'remove'): 1,\n",
              "         ('sports', 'remove', 'mind'): 1,\n",
              "         ('remove', 'mind', 'from'): 1,\n",
              "         ('mind', 'from', 'gutter'): 1,\n",
              "         ('from', 'gutter', 'is'): 1,\n",
              "         ('gutter', 'is', 'more'): 1,\n",
              "         ('more', 'my', 'idea'): 1,\n",
              "         ('my', 'idea', 'of'): 6,\n",
              "         ('idea', 'of', 'a'): 5,\n",
              "         ('of', 'a', 'good'): 2,\n",
              "         ('a', 'good', 'time'): 53,\n",
              "         ('good', 'time', 'i'): 15,\n",
              "         ('time', 'i', 'love'): 16,\n",
              "         ('love', 'to', 'laugh'): 68,\n",
              "         ('to', 'laugh', 'i'): 18,\n",
              "         ('laugh', 'i', 'love'): 2,\n",
              "         ('love', 'to', 'make'): 9,\n",
              "         ('to', 'make', 'jokes'): 3,\n",
              "         ('make', 'jokes', 'sometimes'): 1,\n",
              "         ('jokes', 'sometimes', 'at'): 1,\n",
              "         ('sometimes', 'at', 'other'): 1,\n",
              "         ('at', 'other', 's'): 1,\n",
              "         ('other', 's', 'expense'): 1,\n",
              "         ('s', 'expense', 'but'): 1,\n",
              "         ('expense', 'but', 'like'): 1,\n",
              "         ('said', 'i', 'can'): 2,\n",
              "         ('i', 'can', 'take'): 5,\n",
              "         ('can', 'take', 'it'): 2,\n",
              "         ('take', 'it', 'too'): 1,\n",
              "         ('it', 'too', 'i'): 3,\n",
              "         ('too', 'i', 'love'): 5,\n",
              "         ('i', 'love', 'people'): 12,\n",
              "         ('love', 'people', 'who'): 3,\n",
              "         ('people', 'who', 'are'): 44,\n",
              "         ('who', 'are', 'creative'): 1,\n",
              "         ('are', 'creative', 'but'): 1,\n",
              "         ('creative', 'but', 'don'): 1,\n",
              "         ('but', 'don', 't'): 33,\n",
              "         ('don', 't', 'insist'): 1,\n",
              "         ('t', 'insist', 'that'): 1,\n",
              "         ('insist', 'that', 'they'): 1,\n",
              "         ('that', 'they', 'are'): 2,\n",
              "         ('they', 'are', 'artists'): 1,\n",
              "         ('are', 'artists', 'people'): 1,\n",
              "         ('artists', 'people', 'who'): 1,\n",
              "         ('people', 'who', 'have'): 11,\n",
              "         ('who', 'have', 'passion'): 1,\n",
              "         ('have', 'passion', 'and'): 2,\n",
              "         ('passion', 'and', 'people'): 1,\n",
              "         ('and', 'people', 'who'): 4,\n",
              "         ('who', 'are', 'driven'): 1,\n",
              "         ('are', 'driven', 'i'): 1,\n",
              "         ('driven', 'i', 'am'): 1,\n",
              "         ('i', 'am', 'attracted'): 6,\n",
              "         ('am', 'attracted', 'to'): 7,\n",
              "         ('attracted', 'to', 'people'): 5,\n",
              "         ('to', 'people', 'who'): 8,\n",
              "         ('who', 'are', 'articulate'): 1,\n",
              "         ('are', 'articulate', 'and'): 1,\n",
              "         ('articulate', 'and', 'can'): 1,\n",
              "         ('and', 'can', 'think'): 2,\n",
              "         ('can', 'think', 'critically'): 1,\n",
              "         ('think', 'critically', 'and'): 1,\n",
              "         ('critically', 'and', 'people'): 1,\n",
              "         ('people', 'who', 'understand'): 1,\n",
              "         ('who', 'understand', 'that'): 2,\n",
              "         ('understand', 'that', 'actions'): 1,\n",
              "         ('that', 'actions', 'speak'): 1,\n",
              "         ('actions', 'speak', 'louder'): 2,\n",
              "         ('speak', 'louder', 'than'): 2,\n",
              "         ('louder', 'than', 'words'): 2,\n",
              "         ('than', 'words', 'br'): 2,\n",
              "         ('words', 'br', 'br'): 4,\n",
              "         ('br', 'i', 'am'): 628,\n",
              "         ('i', 'am', 'inquisitive'): 5,\n",
              "         ('am', 'inquisitive', 'imaginative'): 1,\n",
              "         ('inquisitive', 'imaginative', 'and'): 1,\n",
              "         ('imaginative', 'and', 'impulsive'): 1,\n",
              "         ('and', 'impulsive', 'i'): 1,\n",
              "         ('impulsive', 'i', 'm'): 1,\n",
              "         ('i', 'm', 'a'): 729,\n",
              "         ('m', 'a', 'musician'): 5,\n",
              "         ('a', 'musician', 'usually'): 1,\n",
              "         ('musician', 'usually', 'when'): 1,\n",
              "         ('usually', 'when', 'people'): 1,\n",
              "         ('when', 'people', 'need'): 1,\n",
              "         ('people', 'need', 'to'): 1,\n",
              "         ('need', 'to', 'describe'): 2,\n",
              "         ('to', 'describe', 'me'): 11,\n",
              "         ('describe', 'me', 'that'): 1,\n",
              "         ('me', 'that', 's'): 5,\n",
              "         ('that', 's', 'the'): 12,\n",
              "         ('s', 'the', 'first'): 3,\n",
              "         ('the', 'first', 'thing'): 5,\n",
              "         ('first', 'thing', 'that'): 2,\n",
              "         ('thing', 'that', 'pops'): 1,\n",
              "         ('that', 'pops', 'out'): 1,\n",
              "         ('pops', 'out', 'second'): 1,\n",
              "         ('out', 'second', 'is'): 1,\n",
              "         ('second', 'is', 'usually'): 1,\n",
              "         ('is', 'usually', 'something'): 1,\n",
              "         ('usually', 'something', 'about'): 1,\n",
              "         ('something', 'about', 'sarcasm'): 1,\n",
              "         ('about', 'sarcasm', 'of'): 1,\n",
              "         ('sarcasm', 'of', 'humorous'): 1,\n",
              "         ('of', 'humorous', 'self'): 1,\n",
              "         ('humorous', 'self', 'deprecation'): 1,\n",
              "         ('self', 'deprecation', 'third'): 1,\n",
              "         ('deprecation', 'third', 'has'): 1,\n",
              "         ('third', 'has', 'something'): 1,\n",
              "         ('has', 'something', 'to'): 1,\n",
              "         ('something', 'to', 'do'): 3,\n",
              "         ('to', 'do', 'about'): 1,\n",
              "         ('do', 'about', 'beverages'): 1,\n",
              "         ('about', 'beverages', 'people'): 1,\n",
              "         ('beverages', 'people', 'tend'): 1,\n",
              "         ('people', 'tend', 'to'): 6,\n",
              "         ('tend', 'to', 'get'): 8,\n",
              "         ('to', 'get', 'bored'): 2,\n",
              "         ('get', 'bored', 'at'): 1,\n",
              "         ('bored', 'at', 'this'): 1,\n",
              "         ('at', 'this', 'point'): 12,\n",
              "         ('this', 'point', 'i'): 4,\n",
              "         ('point', 'i', 'm'): 3,\n",
              "         ('m', 'a', 'mexican'): 1,\n",
              "         ('a', 'mexican', 'american'): 1,\n",
              "         ('mexican', 'american', 'living'): 1,\n",
              "         ('american', 'living', 'in'): 1,\n",
              "         ('living', 'in', 'hayward'): 1,\n",
              "         ('in', 'hayward', 'california'): 1,\n",
              "         ('hayward', 'california', 'i'): 1,\n",
              "         ('california', 'i', 'm'): 3,\n",
              "         ('i', 'm', '23'): 4,\n",
              "         ('m', '23', 'years'): 3,\n",
              "         ('23', 'years', 'old'): 4,\n",
              "         ('years', 'old', 'and'): 6,\n",
              "         ('old', 'and', 'you'): 1,\n",
              "         ('and', 'you', 'll'): 8,\n",
              "         ('you', 'll', 'know'): 1,\n",
              "         ('ll', 'know', 'a'): 1,\n",
              "         ('know', 'a', 'bit'): 2,\n",
              "         ('a', 'bit', 'more'): 10,\n",
              "         ('bit', 'more', 'when'): 1,\n",
              "         ('more', 'when', 'you'): 1,\n",
              "         ('when', 'you', 'read'): 1,\n",
              "         ('you', 'read', 'my'): 1,\n",
              "         ('read', 'my', 'profile'): 3,\n",
              "         ('my', 'profile', 'i'): 8,\n",
              "         ('profile', 'i', 'm'): 7,\n",
              "         ('i', 'm', 'arrogant'): 3,\n",
              "         ('m', 'arrogant', 'yet'): 1,\n",
              "         ('arrogant', 'yet', 'self'): 1,\n",
              "         ('yet', 'self', 'deprecating'): 1,\n",
              "         ('self', 'deprecating', 'br'): 1,\n",
              "         ('deprecating', 'br', 'br'): 1,\n",
              "         ('br', 'i', 'like'): 175,\n",
              "         ('i', 'like', 'to'): 426,\n",
              "         ('like', 'to', 'compete'): 1,\n",
              "         ('to', 'compete', 'it'): 1,\n",
              "         ('compete', 'it', 'doesn'): 1,\n",
              "         ('it', 'doesn', 't'): 24,\n",
              "         ('doesn', 't', 'matter'): 3,\n",
              "         ('t', 'matter', 'if'): 1,\n",
              "         ('matter', 'if', 'it'): 1,\n",
              "         ('if', 'it', 's'): 22,\n",
              "         ('it', 's', 'pool'): 1,\n",
              "         ('s', 'pool', 'darts'): 1,\n",
              "         ('pool', 'darts', 'air'): 1,\n",
              "         ('darts', 'air', 'hockey'): 1,\n",
              "         ('air', 'hockey', 'chess'): 1,\n",
              "         ('hockey', 'chess', 'skee'): 1,\n",
              "         ('chess', 'skee', 'ball'): 1,\n",
              "         ('skee', 'ball', 'cards'): 1,\n",
              "         ('ball', 'cards', 'or'): 1,\n",
              "         ('cards', 'or', 'board'): 1,\n",
              "         ('or', 'board', 'games'): 1,\n",
              "         ('board', 'games', 'i'): 1,\n",
              "         ('games', 'i', 'like'): 2,\n",
              "         ('like', 'to', 'play'): 18,\n",
              "         ('to', 'play', 'and'): 7,\n",
              "         ('play', 'and', 'i'): 1,\n",
              "         ('and', 'i', 'like'): 64,\n",
              "         ('like', 'to', 'talk'): 5,\n",
              "         ('to', 'talk', 'some'): 1,\n",
              "         ('talk', 'some', 'trash'): 1,\n",
              "         ('some', 'trash', 'while'): 1,\n",
              "         ('trash', 'while', 'doing'): 1,\n",
              "         ('while', 'doing', 'so'): 1,\n",
              "         ('doing', 'so', 'br'): 1,\n",
              "         ('so', 'br', 'br'): 3,\n",
              "         ('br', 'i', 'try'): 12,\n",
              "         ('i', 'try', 'to'): 99,\n",
              "         ('try', 'to', 'go'): 8,\n",
              "         ('to', 'go', 'see'): 1,\n",
              "         ('go', 'see', 'at'): 1,\n",
              "         ('see', 'at', 'least'): 1,\n",
              "         ('at', 'least', '5'): 2,\n",
              "         ('least', '5', 'bands'): 1,\n",
              "         ('5', 'bands', 'a'): 1,\n",
              "         ('bands', 'a', 'month'): 1,\n",
              "         ('a', 'month', 'br'): 1,\n",
              "         ('month', 'br', 'br'): 1,\n",
              "         ('br', 'i', 'm'): 505,\n",
              "         ('i', 'm', 'not'): 346,\n",
              "         ('m', 'not', 'much'): 6,\n",
              "         ('not', 'much', 'of'): 9,\n",
              "         ('much', 'of', 'a'): 11,\n",
              "         ('of', 'a', 'cook'): 1,\n",
              "         ('a', 'cook', 'but'): 1,\n",
              "         ('cook', 'but', 'i'): 4,\n",
              "         ('but', 'i', 'am'): 50,\n",
              "         ('am', 'a', 'huge'): 16,\n",
              "         ('a', 'huge', 'foodie'): 1,\n",
              "         ('huge', 'foodie', 'i'): 1,\n",
              "         ('foodie', 'i', 'love'): 1,\n",
              "         ('i', 'love', 'checking'): 2,\n",
              "         ('love', 'checking', 'out'): 3,\n",
              "         ('checking', 'out', 'new'): 7,\n",
              "         ('out', 'new', 'restaurants'): 2,\n",
              "         ('new', 'restaurants', 'in'): 2,\n",
              "         ('restaurants', 'in', 'town'): 1,\n",
              "         ('in', 'town', 'especially'): 1,\n",
              "         ('town', 'especially', 'with'): 1,\n",
              "         ('especially', 'with', 'someone'): 1,\n",
              "         ('with', 'someone', 'who'): 18,\n",
              "         ('someone', 'who', 'understands'): 2,\n",
              "         ('who', 'understands', 'that'): 2,\n",
              "         ('understands', 'that', 'you'): 1,\n",
              "         ('that', 'you', 'can'): 13,\n",
              "         ('you', 'can', 'like'): 1,\n",
              "         ('can', 'like', 'a'): 1,\n",
              "         ('like', 'a', 'dish'): 1,\n",
              "         ('a', 'dish', 'while'): 1,\n",
              "         ('dish', 'while', 'talking'): 1,\n",
              "         ('while', 'talking', 'about'): 2,\n",
              "         ('talking', 'about', 'what'): 2,\n",
              "         ('about', 'what', 'could'): 1,\n",
              "         ('what', 'could', 'make'): 2,\n",
              "         ('could', 'make', 'it'): 1,\n",
              "         ('make', 'it', 'better'): 1,\n",
              "         ('it', 'better', 'br'): 1,\n",
              "         ('better', 'br', 'br'): 6,\n",
              "         ('br', 'br', 'halloween'): 1,\n",
              "         ('br', 'halloween', 'is'): 1,\n",
              "         ('halloween', 'is', 'my'): 1,\n",
              "         ('is', 'my', 'favorite'): 10,\n",
              "         ('my', 'favorite', 'holiday'): 3,\n",
              "         ('favorite', 'holiday', 'of'): 1,\n",
              "         ('holiday', 'of', 'the'): 1,\n",
              "         ('of', 'the', 'year'): 5,\n",
              "         ('the', 'year', 'i'): 4,\n",
              "         ('year', 'i', 'grew'): 1,\n",
              "         ('up', 'in', 'quite'): 1,\n",
              "         ('in', 'quite', 'possibly'): 1,\n",
              "         ('quite', 'possibly', 'one'): 1,\n",
              "         ('possibly', 'one', 'of'): 1,\n",
              "         ('one', 'of', 'the'): 59,\n",
              "         ('of', 'the', 'most'): 14,\n",
              "         ('the', 'most', 'odious'): 1,\n",
              "         ('most', 'odious', 'places'): 1,\n",
              "         ('odious', 'places', 'on'): 1,\n",
              "         ('places', 'on', 'earth'): 1,\n",
              "         ('on', 'earth', 'a'): 1,\n",
              "         ('earth', 'a', 'city'): 1,\n",
              "         ('a', 'city', 'in'): 1,\n",
              "         ('city', 'in', 'northeastern'): 1,\n",
              "         ('in', 'northeastern', 'mexico'): 1,\n",
              "         ('northeastern', 'mexico', 'but'): 1,\n",
              "         ('mexico', 'but', 'it'): 1,\n",
              "         ('but', 'it', 's'): 38,\n",
              "         ('it', 's', 'home'): 1,\n",
              "         ('s', 'home', 'so'): 1,\n",
              "         ('home', 'so', 'i'): 1,\n",
              "         ('so', 'i', 'miss'): 1,\n",
              "         ('i', 'miss', 'it'): 4,\n",
              "         ('miss', 'it', 'terribly'): 1,\n",
              "         ('it', 'terribly', 'i'): 1,\n",
              "         ('terribly', 'i', 'came'): 1,\n",
              "         ('i', 'came', 'to'): 15,\n",
              "         ('came', 'to', 'the'): 12,\n",
              "         ('to', 'the', 'bay'): 71,\n",
              "         ('the', 'bay', 'area'): 220,\n",
              "         ('bay', 'area', 'for'): 31,\n",
              "         ('area', 'for', 'college'): 2,\n",
              "         ('for', 'college', 'finished'): 1,\n",
              "         ('college', 'finished', 'that'): 1,\n",
              "         ('finished', 'that', 'and'): 1,\n",
              "         ('that', 'and', 'have'): 1,\n",
              "         ('and', 'have', 'decided'): 1,\n",
              "         ('have', 'decided', 'to'): 2,\n",
              "         ('decided', 'to', 'stick'): 1,\n",
              "         ('to', 'stick', 'around'): 3,\n",
              "         ('stick', 'around', 'for'): 3,\n",
              "         ('around', 'for', 'the'): 1,\n",
              "         ('for', 'the', 'foreseeable'): 3,\n",
              "         ('the', 'foreseeable', 'future'): 3,\n",
              "         ('foreseeable', 'future', 'br'): 1,\n",
              "         ('future', 'br', 'br'): 5,\n",
              "         ('br', 'i', 'love'): 246,\n",
              "         ('i', 'love', 'movies'): 17,\n",
              "         ('love', 'movies', 'and'): 3,\n",
              "         ('movies', 'and', 'i'): 3,\n",
              "         ('and', 'i', 'used'): 5,\n",
              "         ('i', 'used', 'to'): 40,\n",
              "         ('used', 'to', 'love'): 1,\n",
              "         ('to', 'love', 'books'): 1,\n",
              "         ('love', 'books', 'recently'): 1,\n",
              "         ('books', 'recently', 'i'): 1,\n",
              "         ('recently', 'i', 'haven'): 1,\n",
              "         ('i', 'haven', 't'): 50,\n",
              "         ('haven', 't', 'given'): 3,\n",
              "         ('t', 'given', 'myself'): 1,\n",
              "         ('given', 'myself', 'enough'): 1,\n",
              "         ('myself', 'enough', 'time'): 1,\n",
              "         ('enough', 'time', 'for'): 1,\n",
              "         ('time', 'for', 'either'): 1,\n",
              "         ('for', 'either', 'br'): 1,\n",
              "         ('either', 'br', 'br'): 2,\n",
              "         ('br', 'i', 'write'): 5,\n",
              "         ('i', 'write', 'computer'): 1,\n",
              "         ('write', 'computer', 'programs'): 1,\n",
              "         ('computer', 'programs', 'for'): 1,\n",
              "         ('programs', 'for', 'a'): 1,\n",
              "         ('for', 'a', 'living'): 30,\n",
              "         ('a', 'living', 'br'): 6,\n",
              "         ('living', 'br', 'br'): 6,\n",
              "         ('br', 'br', 'as'): 36,\n",
              "         ('br', 'as', 'my'): 2,\n",
              "         ('as', 'my', 'late'): 1,\n",
              "         ('my', 'late', 'grandfather'): 1,\n",
              "         ('late', 'grandfather', 'once'): 1,\n",
              "         ('grandfather', 'once', 'said'): 1,\n",
              "         ('once', 'said', 'to'): 3,\n",
              "         ('said', 'to', 'me'): 4,\n",
              "         ('to', 'me', 'remember'): 1,\n",
              "         ('me', 'remember', 'we'): 1,\n",
              "         ('remember', 'we', 're'): 1,\n",
              "         ('we', 're', 'not'): 4,\n",
              "         ('re', 'not', 'stubborn'): 1,\n",
              "         ('not', 'stubborn', 'we'): 1,\n",
              "         ('stubborn', 'we', 'merely'): 1,\n",
              "         ('we', 'merely', 'have'): 1,\n",
              "         ('merely', 'have', 'firm'): 1,\n",
              "         ('have', 'firm', 'convictions'): 2,\n",
              "         ('firm', 'convictions', 'i'): 2,\n",
              "         ('convictions', 'i', 'have'): 1,\n",
              "         ('i', 'have', 'firm'): 1,\n",
              "         ('convictions', 'i', 've'): 1,\n",
              "         ('i', 've', 'been'): 205,\n",
              "         ('ve', 'been', 'known'): 10,\n",
              "         ('been', 'known', 'to'): 18,\n",
              "         ('known', 'to', 'engage'): 1,\n",
              "         ('to', 'engage', 'in'): 4,\n",
              "         ('engage', 'in', 'vigorous'): 1,\n",
              "         ('in', 'vigorous', 'conversation'): 1,\n",
              "         ('vigorous', 'conversation', 'about'): 1,\n",
              "         ('conversation', 'about', 'politics'): 1,\n",
              "         ('about', 'politics', 'economics'): 1,\n",
              "         ('politics', 'economics', 'and'): 1,\n",
              "         ('economics', 'and', 'international'): 1,\n",
              "         ('and', 'international', 'relations'): 1,\n",
              "         ('international', 'relations', 'programming'): 1,\n",
              "         ('relations', 'programming', 'languages'): 1,\n",
              "         ('programming', 'languages', 'web'): 1,\n",
              "         ('languages', 'web', 'frameworks'): 1,\n",
              "         ('web', 'frameworks', 'and'): 1,\n",
              "         ('frameworks', 'and', 'software'): 1,\n",
              "         ('and', 'software', 'architectures'): 1,\n",
              "         ('software', 'architectures', 'could'): 1,\n",
              "         ('architectures', 'could', 'also'): 1,\n",
              "         ('could', 'also', 'make'): 1,\n",
              "         ('also', 'make', 'that'): 1,\n",
              "         ('make', 'that', 'list'): 1,\n",
              "         ('that', 'list', 'br'): 1,\n",
              "         ('list', 'br', 'br'): 3,\n",
              "         ('love', 'to', 'travel'): 71,\n",
              "         ('to', 'travel', 'i'): 13,\n",
              "         ...})"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# words = (\n",
        "#     df['essay0'].str.lower().\n",
        "#     str.replace(\"[^\\w\\s]\", \" \").\n",
        "#     fillna(' ').\n",
        "#     str.split()\n",
        "# )\n",
        "\n",
        "words = (\n",
        "    docs_seuss.\n",
        "    str.lower().\n",
        "    str.replace(\"[^\\w\\s]\", \" \").\n",
        "    str.split()\n",
        ")\n",
        "\n",
        "def fun(word):\n",
        "  return zip(word, word[1:], word[2:])\n",
        "\n",
        "words.apply(fun).apply(Counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq8v9M9tlNK2",
        "outputId": "447b9ce0-b401-4d99-d9e5-48b16f1e35bc"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "green_eggs_and_ham                {('i', 'am', 'sam'): 2, ('am', 'sam', 'i'): 1,...\n",
              "cat_in_the_hat                    {('the', 'sun', 'did'): 1, ('sun', 'did', 'not...\n",
              "fox_in_socks                      {('fox', 'socks', 'box'): 1, ('socks', 'box', ...\n",
              "hop_on_pop                        {('up', 'pup', 'pup'): 1, ('pup', 'pup', 'is')...\n",
              "horton_hears_a_who                {('on', 'the', 'fifteenth'): 1, ('the', 'fifte...\n",
              "how_the_grinch_stole_christmas    {('every', 'who', 'down'): 4, ('who', 'down', ...\n",
              "oh_the_places_youll_go            {('congratulations', 'today', 'is'): 1, ('toda...\n",
              "one_fish_two_fish                 {('one', 'fish', 'two'): 1, ('fish', 'two', 'f...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qmIRQZIEovE1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}